{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from urllib.request import urlopen\n",
    "import urllib\n",
    "from requests import get\n",
    "import requests\n",
    "from requests.exceptions import RequestException\n",
    "from contextlib import closing\n",
    "from bs4 import BeautifulSoup\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_get(url):\n",
    "    \"\"\"\n",
    "    Attempts to get the content at \"url\" by making an HTTP GET request.\n",
    "    If the content-type of response is some kind of HTML/XML, return the\n",
    "    text content, otherwise return None.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with closing(get(url, stream=True)) as resp:\n",
    "            if is_good_response (resp):\n",
    "                return resp.content\n",
    "            else:\n",
    "                return None\n",
    "    except RequestException as e:\n",
    "        log_error('Error during requests to {0}: {1}'.format(url, str(e)))\n",
    "        return '$'\n",
    "    \n",
    "def is_good_response (resp):\n",
    "    \"\"\"\n",
    "Returns True if the response seems to be HTML, False otherwise\"\"\"\n",
    "    content_type = resp.headers['Content-Type'].lower()\n",
    "    return (resp.status_code == 200\n",
    "        and content_type is not None\n",
    "        and content_type.find('html') > -1)\n",
    "def log_error(e):\n",
    "    \"\"\" It is always a good idea to log errors.\n",
    "    This function just prints them, but you can\n",
    "    make it do anything.\"\"\"\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(url, tag='', attrbute='', start=''):\n",
    "    data=simple_get(url)\n",
    "    links=[]\n",
    "    if data != None:\n",
    "        soup=BeautifulSoup(data)\n",
    "        for link in soup.findAll(tag, attrs={attrbute:re.compile(start, flags = re.IGNORECASE)}):\n",
    "            links.append(link.get(attrbute))\n",
    "    \n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during requests to https://mloss.org/: HTTPSConnectionPool(host='mloss.org', port=443): Max retries exceeded with url: / (Caused by SSLError(SSLError(\"bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')])\")))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9906"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1. Count the maximum number of URLs in each page.\n",
    "li=get_links(\"https://en.wikipedia.org/wiki/Machine_learning\", tag='a', attrbute='href', start = '^http')\n",
    "li2=[]\n",
    "   \n",
    "for x in range(len(li)):\n",
    "    li2.append(get_links(li[x],tag='a', attrbute='href', start = '^http'))\n",
    "li2=list(chain(*li2))\n",
    "len(li2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during requests to https://mloss.org/: HTTPSConnectionPool(host='mloss.org', port=443): Max retries exceeded with url: / (Caused by SSLError(SSLError(\"bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')])\")))\n"
     ]
    }
   ],
   "source": [
    "#2. Save all the URLs counted in a .txt file.\n",
    "li=get_links(\"https://en.wikipedia.org/wiki/Machine_learning\", tag='a', attrbute='href', start = '^http')\n",
    "\n",
    "li2=[]  \n",
    "for x in range(100):\n",
    "    li2.append(get_links(li[x],tag='a', attrbute='href', start = '^http'))\n",
    "a=range(1,100)\n",
    "for i in a:\n",
    "    with open(\"{}.txt\".format(i), \"w\", encoding='utf-8') as f:\n",
    "        for i2 in li2:\n",
    "            f.write(str(i2).strip('[]'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From 1\n",
      "Wikipedia, 1\n",
      "encyclopedia 1\n",
      "navigation 1\n",
      "journal, 1\n",
      "(journal). 1\n",
      "\"Statistical 1\n",
      "redirects 1\n",
      "here. 1\n",
      "linguistics, 1\n",
      "acquisition. 1\n",
      "Scientific 1\n",
      "instructions 1\n",
      "anddata 1\n",
      "Problems 1\n",
      "AutoML 1\n",
      "rank 1\n",
      "Grammar 1\n",
      "induction 1\n",
      "learning.mw-parser-output 1\n",
      ".nobold{font-weight:normal}(classification 1\n",
      "• 1\n",
      "regression) 1\n",
      "Ensembles 1\n",
      "Bagging 1\n",
      "Boosting 1\n",
      "forest 1\n",
      "Linear 1\n",
      "Naive 1\n",
      "Perceptron 1\n",
      "Relevance 1\n",
      "(RVM) 1\n",
      "(SVM) 1\n",
      "BIRCH 1\n",
      "CURE 1\n",
      "k-means 1\n",
      "Expectation–maximization 1\n",
      "(EM) 1\n",
      "DBSCAN 1\n",
      "OPTICS 1\n",
      "Mean-shift 1\n",
      "Factor 1\n",
      "CCA 1\n",
      "ICA 1\n",
      "LDA 1\n",
      "NMF 1\n",
      "PCA 1\n",
      "t-SNE 1\n",
      "Graphical 1\n",
      "net 1\n",
      "Conditional 1\n",
      "Hidden 1\n",
      "Local 1\n",
      "factor 1\n",
      "Autoencoder 1\n",
      "DeepDream 1\n",
      "Multilayer 1\n",
      "perceptron 1\n",
      "RNN 1\n",
      "LSTM 1\n",
      "GRU 1\n",
      "Restricted 1\n",
      "Boltzmann 1\n",
      "GAN 1\n",
      "SOM 1\n",
      "Convolutional 1\n",
      "U-Net 1\n",
      "Q-learning 1\n",
      "SARSA 1\n",
      "Temporal 1\n",
      "(TD) 1\n",
      "Bias–variance 1\n",
      "Empirical 1\n",
      "Occam 1\n",
      "PAC 1\n",
      "VC 1\n",
      "venues 1\n",
      "NeurIPS 1\n",
      "ICML 1\n",
      "ML 1\n",
      "JMLR 1\n",
      "ArXiv:cs.LG 1\n",
      "Related 1\n",
      "vte 1\n",
      "(ML) 1\n",
      "instructions, 1\n",
      "instead. 1\n",
      "\"training 1\n",
      "data\", 1\n",
      "task.[1][2]:2 1\n",
      "wide 1\n",
      "applications, 1\n",
      "email 1\n",
      "filtering 1\n",
      "infeasible 1\n",
      "conventional 1\n",
      "effectively 1\n",
      "making 1\n",
      "computers. 1\n",
      "delivers 1\n",
      "exploratory 1\n",
      "learning.[3][4] 1\n",
      "business 1\n",
      "analytics. 1\n",
      "Contents 1\n",
      "Overview 1\n",
      "1.1 1\n",
      "2.1 1\n",
      "2.2 1\n",
      "2.3 1\n",
      "Approaches 1\n",
      "4.1 1\n",
      "4.1.1 1\n",
      "4.1.2 1\n",
      "4.1.3 1\n",
      "4.1.4 1\n",
      "4.1.5 1\n",
      "4.1.6 1\n",
      "4.1.7 1\n",
      "4.1.8 1\n",
      "4.2 1\n",
      "4.2.1 1\n",
      "4.2.2 1\n",
      "4.2.3 1\n",
      "4.2.4 1\n",
      "4.2.5 1\n",
      "4.2.6 1\n",
      "4.3 1\n",
      "4.3.1 1\n",
      "Applications 1\n",
      "Limitations 1\n",
      "6.1 1\n",
      "Bias 1\n",
      "7 1\n",
      "assessments 1\n",
      "9 1\n",
      "9.1 1\n",
      "9.2 1\n",
      "editions 1\n",
      "9.3 1\n",
      "Journals 1\n",
      "Conferences 1\n",
      "12 1\n",
      "References 1\n",
      "14 1\n",
      "reading 1\n",
      "Overview[edit] 1\n",
      "Samuel.[5] 1\n",
      "Tom 1\n",
      "Mitchell 1\n",
      "widely 1\n",
      "quoted, 1\n",
      "formal 1\n",
      "field: 1\n",
      "E 1\n",
      "T 1\n",
      "P 1\n",
      "T, 1\n",
      "measured 1\n",
      "P, 1\n",
      "E.\"[6] 1\n",
      "offers 1\n",
      "fundamentally 1\n",
      "operational 1\n",
      "cognitive 1\n",
      "terms. 1\n",
      "Alan 1\n",
      "his 1\n",
      "paper 1\n",
      "\"Computing 1\n",
      "Machinery 1\n",
      "think?\" 1\n",
      "replaced 1\n",
      "(as 1\n",
      "entities) 1\n",
      "do?\".[7] 1\n",
      "characteristics 1\n",
      "possessed 1\n",
      "implications 1\n",
      "constructing 1\n",
      "exposed. 1\n",
      "tasks[edit] 1\n",
      "regions 1\n",
      "separated 1\n",
      "boundary. 1\n",
      "boundary 1\n",
      "circles 1\n",
      "white. 1\n",
      "categories. 1\n",
      "outputs. 1\n",
      "determining 1\n",
      "images 1\n",
      "object 1\n",
      "input), 1\n",
      "output) 1\n",
      "designating 1\n",
      "cases, 1\n",
      "partially 1\n",
      "available, 1\n",
      "feedback.[clarification 1\n",
      "incomplete 1\n",
      "portion 1\n",
      "doesn't 1\n",
      "values. 1\n",
      "filters 1\n",
      "incoming 1\n",
      "email, 1\n",
      "folder 1\n",
      "file 1\n",
      "email. 1\n",
      "identifies 1\n",
      "spam 1\n",
      "\"spam\" 1\n",
      "\"not 1\n",
      "spam\", 1\n",
      "Boolean 1\n",
      "false. 1\n",
      "outputs, 1\n",
      "temperature, 1\n",
      "length, 1\n",
      "price 1\n",
      "number 1\n",
      "\"features\", 1\n",
      "Active 1\n",
      "(training 1\n",
      "labels) 1\n",
      "budget, 1\n",
      "optimize 1\n",
      "choice 1\n",
      "interactively, 1\n",
      "presented 1\n",
      "labeling. 1\n",
      "feedback 1\n",
      "opponent.[2]:3 1\n",
      "specialized 1\n",
      "topic 1\n",
      "modeling, 1\n",
      "cover 1\n",
      "topics. 1\n",
      "unobservable 1\n",
      "problems. 1\n",
      "Meta 1\n",
      "experience. 1\n",
      "developmental 1\n",
      "robotics, 1\n",
      "experiences, 1\n",
      "curriculum, 1\n",
      "cumulatively 1\n",
      "skills 1\n",
      "self-guided 1\n",
      "exploration 1\n",
      "humans. 1\n",
      "These 1\n",
      "robots 1\n",
      "guidance 1\n",
      "active 1\n",
      "maturation, 1\n",
      "motor 1\n",
      "synergies, 1\n",
      "imitation.[clarification 1\n",
      "fields[edit] 1\n",
      "Timeline 1\n",
      "American 1\n",
      "pioneer 1\n",
      "gaming 1\n",
      "Learning\" 1\n",
      "IBM.[8] 1\n",
      "1960s 1\n",
      "Nilsson's 1\n",
      "classification.[9] 1\n",
      "interest 1\n",
      "1970s, 1\n",
      "described 1\n",
      "Duda 1\n",
      "1973. 1\n",
      "[10] 1\n",
      "1981 1\n",
      "teaching 1\n",
      "strategies 1\n",
      "40 1\n",
      "characters 1\n",
      "(26 1\n",
      "letters, 1\n",
      "digits, 1\n",
      "symbols) 1\n",
      "terminal. 1\n",
      "[11] 1\n",
      "As 1\n",
      "endeavor, 1\n",
      "grew 1\n",
      "quest 1\n",
      "Already 1\n",
      "early 1\n",
      "days 1\n",
      "discipline, 1\n",
      "interested 1\n",
      "attempted 1\n",
      "termed 1\n",
      "\"neural 1\n",
      "networks\"; 1\n",
      "perceptrons 1\n",
      "later 1\n",
      "reinventions 1\n",
      "generalized 1\n",
      "statistics.[12] 1\n",
      "employed, 1\n",
      "diagnosis.[13]:488 1\n",
      "emphasis 1\n",
      "logical, 1\n",
      "knowledge-based 1\n",
      "caused 1\n",
      "rift 1\n",
      "plagued 1\n",
      "acquisition 1\n",
      "representation.[13]:488 1\n",
      "1980, 1\n",
      "expert 1\n",
      "dominate 1\n",
      "favor.[14] 1\n",
      "Work 1\n",
      "symbolic/knowledge-based 1\n",
      "did 1\n",
      "continue 1\n",
      "programming, 1\n",
      "now 1\n",
      "proper, 1\n",
      "retrieval.[13]:708–710; 1\n",
      "755 1\n",
      "abandoned 1\n",
      "around 1\n",
      "line, 1\n",
      "too, 1\n",
      "AI/CS 1\n",
      "\"connectionism\", 1\n",
      "disciplines 1\n",
      "Hopfield, 1\n",
      "Rumelhart 1\n",
      "Hinton. 1\n",
      "Their 1\n",
      "main 1\n",
      "success 1\n",
      "came 1\n",
      "mid-1980s 1\n",
      "reinvention 1\n",
      "backpropagation.[13]:25 1\n",
      "reorganized 1\n",
      "started 1\n",
      "flourish 1\n",
      "1990s. 1\n",
      "achieving 1\n",
      "tackling 1\n",
      "solvable 1\n",
      "nature. 1\n",
      "shifted 1\n",
      "focus 1\n",
      "away 1\n",
      "inherited 1\n",
      "borrowed 1\n",
      "theory.[14] 1\n",
      "benefited 1\n",
      "availability 1\n",
      "digitized 1\n",
      "distribute 1\n",
      "Internet. 1\n",
      "mining[edit] 1\n",
      "employ 1\n",
      "overlap 1\n",
      "significantly, 1\n",
      "prediction, 1\n",
      "(previously) 1\n",
      "(this 1\n",
      "databases). 1\n",
      "goals; 1\n",
      "hand, 1\n",
      "employs 1\n",
      "\"unsupervised 1\n",
      "preprocessing 1\n",
      "accuracy. 1\n",
      "Much 1\n",
      "confusion 1\n",
      "communities 1\n",
      "(which 1\n",
      "conferences 1\n",
      "journals, 1\n",
      "ECML 1\n",
      "PKDD 1\n",
      "major 1\n",
      "exception) 1\n",
      "comes 1\n",
      "basic 1\n",
      "with: 1\n",
      "evaluated 1\n",
      "reproduce 1\n",
      "(KDD) 1\n",
      "Evaluated 1\n",
      "uninformed 1\n",
      "(unsupervised) 1\n",
      "easily 1\n",
      "outperformed 1\n",
      "typical 1\n",
      "KDD 1\n",
      "task, 1\n",
      "due 1\n",
      "unavailability 1\n",
      "optimization[edit] 1\n",
      "intimate 1\n",
      "ties 1\n",
      "optimization: 1\n",
      "formulated 1\n",
      "Loss 1\n",
      "discrepancy 1\n",
      "actual 1\n",
      "(for 1\n",
      "wants 1\n",
      "assign 1\n",
      "instances, 1\n",
      "pre-assigned 1\n",
      "examples). 1\n",
      "arises 1\n",
      "generalization: 1\n",
      "minimize 1\n",
      "minimizing 1\n",
      "samples.[15] 1\n",
      "statistics[edit] 1\n",
      "distinct 1\n",
      "goal: 1\n",
      "draws 1\n",
      "population 1\n",
      "inferences 1\n",
      "sample, 1\n",
      "generalizable 1\n",
      "patterns.[16] 1\n",
      "According 1\n",
      "ideas 1\n",
      "methodological 1\n",
      "principles 1\n",
      "tools, 1\n",
      "long 1\n",
      "pre-history 1\n",
      "statistics.[17] 1\n",
      "He 1\n",
      "suggested 1\n",
      "placeholder 1\n",
      "field.[17] 1\n",
      "Leo 1\n",
      "Breiman 1\n",
      "distinguished 1\n",
      "modelling 1\n",
      "paradigms: 1\n",
      "model,[18] 1\n",
      "wherein 1\n",
      "\"algorithmic 1\n",
      "model\" 1\n",
      "means 1\n",
      "forest. 1\n",
      "statisticians 1\n",
      "combined 1\n",
      "learning.[19] 1\n",
      "Theory[edit] 1\n",
      "articles: 1\n",
      "core 1\n",
      "generalize 1\n",
      "experience.[2][20] 1\n",
      "Generalization 1\n",
      "accurately 1\n",
      "new, 1\n",
      "examples/tasks 1\n",
      "experienced 1\n",
      "distribution 1\n",
      "(considered 1\n",
      "occurrences) 1\n",
      "enables 1\n",
      "produce 1\n",
      "sufficiently 1\n",
      "accurate 1\n",
      "cases. 1\n",
      "branch 1\n",
      "theory. 1\n",
      "finite 1\n",
      "future 1\n",
      "uncertain, 1\n",
      "yield 1\n",
      "guarantees 1\n",
      "bounds 1\n",
      "quite 1\n",
      "common. 1\n",
      "bias–variance 1\n",
      "decomposition 1\n",
      "quantify 1\n",
      "error. 1\n",
      "generalization, 1\n",
      "should 1\n",
      "match 1\n",
      "complex 1\n",
      "underfit 1\n",
      "increased 1\n",
      "response, 1\n",
      "error 1\n",
      "decreases. 1\n",
      "But 1\n",
      "too 1\n",
      "complex, 1\n",
      "subject 1\n",
      "poorer.[21] 1\n",
      "bounds, 1\n",
      "theorists 1\n",
      "feasibility 1\n",
      "considered 1\n",
      "feasible 1\n",
      "done 1\n",
      "results. 1\n",
      "classes 1\n",
      "Approaches[edit] 1\n",
      "differ 1\n",
      "approach, 1\n",
      "solve. 1\n",
      "outputs.[22] 1\n",
      "supervisory 1\n",
      "signal. 1\n",
      "array 1\n",
      "Through 1\n",
      "iterative 1\n",
      "inputs.[23] 1\n",
      "optimal 1\n",
      "allow 1\n",
      "task.[6] 1\n",
      "regression.[24] 1\n",
      "values, 1\n",
      "numerical 1\n",
      "Similarity 1\n",
      "measures 1\n",
      "are. 1\n",
      "ranking, 1\n",
      "visual 1\n",
      "identity 1\n",
      "tracking, 1\n",
      "face 1\n",
      "verification, 1\n",
      "speaker 1\n",
      "verification. 1\n",
      "case 1\n",
      "semi-supervised 1\n",
      "missing 1\n",
      "labels, 1\n",
      "nevertheless 1\n",
      "weakly 1\n",
      "noisy, 1\n",
      "limited, 1\n",
      "imprecise; 1\n",
      "however, 1\n",
      "cheaper 1\n",
      "obtain, 1\n",
      "larger 1\n",
      "sets.[25] 1\n",
      "therefore 1\n",
      "labeled, 1\n",
      "categorized. 1\n",
      "Instead 1\n",
      "responding 1\n",
      "feedback, 1\n",
      "react 1\n",
      "absence 1\n",
      "piece 1\n",
      "central 1\n",
      "statistics,[26] 1\n",
      "though 1\n",
      "involving 1\n",
      "summarizing 1\n",
      "explaining 1\n",
      "assignment 1\n",
      "(called 1\n",
      "clusters) 1\n",
      "predesignated 1\n",
      "criteria, 1\n",
      "clusters 1\n",
      "dissimilar. 1\n",
      "metric 1\n",
      "evaluated, 1\n",
      "internal 1\n",
      "compactness, 1\n",
      "cluster, 1\n",
      "separation, 1\n",
      "clusters. 1\n",
      "estimated 1\n",
      "connectivity. 1\n",
      "agents 1\n",
      "ought 1\n",
      "maximize 1\n",
      "notion 1\n",
      "cumulative 1\n",
      "reward. 1\n",
      "Due 1\n",
      "generality, 1\n",
      "disciplines, 1\n",
      "operations 1\n",
      "research, 1\n",
      "simulation-based 1\n",
      "optimization, 1\n",
      "multi-agent 1\n",
      "swarm 1\n",
      "(MDP). 1\n",
      "Many 1\n",
      "techniques.[27] 1\n",
      "assume 1\n",
      "MDP, 1\n",
      "infeasible. 1\n",
      "opponent. 1\n",
      "1982 1\n",
      "along 1\n",
      "capable 1\n",
      "self-learning 1\n",
      "Crossbar 1\n",
      "Array 1\n",
      "(CAA). 1\n",
      "[28] 1\n",
      "rewards 1\n",
      "teacher 1\n",
      "advices. 1\n",
      "computes, 1\n",
      "fashion, 1\n",
      "(feelings) 1\n",
      "driven 1\n",
      "cognition 1\n",
      "emotion. 1\n",
      "[29] 1\n",
      "updates 1\n",
      "W 1\n",
      "=||w(a,s)|| 1\n",
      "iteration 1\n",
      "executes 1\n",
      "following 1\n",
      "routine: 1\n",
      "a; 1\n",
      "Receive 1\n",
      "s’; 1\n",
      "Compute 1\n",
      "v(s’); 1\n",
      "Update 1\n",
      "w’(a,s) 1\n",
      "= 1\n",
      "w(a,s) 1\n",
      "+ 1\n",
      "v(s’). 1\n",
      "input, 1\n",
      "s, 1\n",
      "behavior) 1\n",
      "a. 1\n",
      "neither 1\n",
      "nor 1\n",
      "advice 1\n",
      "backpropagated 1\n",
      "(secondary 1\n",
      "reinforcement) 1\n",
      "situation. 1\n",
      "exists 1\n",
      "environments, 1\n",
      "behaves, 1\n",
      "initially 1\n",
      "once 1\n",
      "situations 1\n",
      "encountered 1\n",
      "After 1\n",
      "receiving 1\n",
      "genome 1\n",
      "(species) 1\n",
      "seeking 1\n",
      "behavior, 1\n",
      "desirable 1\n",
      "undesirable 1\n",
      "[30] 1\n",
      "Several 1\n",
      "training.[31] 1\n",
      "Classic 1\n",
      "analysis. 1\n",
      "preserve 1\n",
      "transform 1\n",
      "makes 1\n",
      "useful, 1\n",
      "pre-processing 1\n",
      "before 1\n",
      "reconstruction 1\n",
      "coming 1\n",
      "data-generating 1\n",
      "distribution, 1\n",
      "faithful 1\n",
      "configurations 1\n",
      "implausible 1\n",
      "distribution. 1\n",
      "replaces 1\n",
      "manual 1\n",
      "engineering, 1\n",
      "unsupervised. 1\n",
      "multilayer 1\n",
      "perceptrons, 1\n",
      "independent 1\n",
      "component 1\n",
      "autoencoders, 1\n",
      "factorization[32] 1\n",
      "clustering.[33][34][35] 1\n",
      "Manifold 1\n",
      "low-dimensional. 1\n",
      "coding 1\n",
      "sparse, 1\n",
      "zeros. 1\n",
      "subspace 1\n",
      "low-dimensional 1\n",
      "directly 1\n",
      "tensor 1\n",
      "multidimensional 1\n",
      "reshaping 1\n",
      "higher-dimensional 1\n",
      "vectors.[36] 1\n",
      "levels 1\n",
      "representation, 1\n",
      "hierarchy 1\n",
      "features, 1\n",
      "higher-level, 1\n",
      "abstract 1\n",
      "generating) 1\n",
      "lower-level 1\n",
      "argued 1\n",
      "intelligent 1\n",
      "disentangles 1\n",
      "factors 1\n",
      "variation 1\n",
      "data.[37] 1\n",
      "motivated 1\n",
      "fact 1\n",
      "mathematically 1\n",
      "computationally 1\n",
      "convenient 1\n",
      "process. 1\n",
      "real-world 1\n",
      "video, 1\n",
      "sensory 1\n",
      "yielded 1\n",
      "attempts 1\n",
      "algorithmically 1\n",
      "define 1\n",
      "alternative 1\n",
      "examination, 1\n",
      "combination 1\n",
      "functions, 1\n",
      "assumed 1\n",
      "strongly 1\n",
      "NP-hard 1\n",
      "approximately.[38] 1\n",
      "popular 1\n",
      "K-SVD 1\n",
      "algorithm. 1\n",
      "contexts. 1\n",
      "belongs. 1\n",
      "built, 1\n",
      "corresponding 1\n",
      "dictionary. 1\n",
      "de-noising. 1\n",
      "idea 1\n",
      "clean 1\n",
      "patch 1\n",
      "dictionary, 1\n",
      "noise 1\n",
      "cannot.[39] 1\n",
      "detection[edit] 1\n",
      "items, 1\n",
      "events 1\n",
      "raise 1\n",
      "suspicions 1\n",
      "differing 1\n",
      "significantly 1\n",
      "data.[40] 1\n",
      "anomalous 1\n",
      "issue 1\n",
      "bank 1\n",
      "fraud, 1\n",
      "structural 1\n",
      "defect, 1\n",
      "errors 1\n",
      "text. 1\n",
      "Anomalies 1\n",
      "outliers, 1\n",
      "novelties, 1\n",
      "noise, 1\n",
      "exceptions.[41] 1\n",
      "abuse 1\n",
      "interesting 1\n",
      "objects, 1\n",
      "unexpected 1\n",
      "bursts 1\n",
      "activity. 1\n",
      "adhere 1\n",
      "(in 1\n",
      "algorithms) 1\n",
      "unless 1\n",
      "appropriately. 1\n",
      "micro-clusters 1\n",
      "formed 1\n",
      "patterns.[42] 1\n",
      "Three 1\n",
      "categories 1\n",
      "exist.[43] 1\n",
      "anomalies 1\n",
      "assumption 1\n",
      "normal, 1\n",
      "looking 1\n",
      "seem 1\n",
      "remainder 1\n",
      "\"normal\" 1\n",
      "\"abnormal\" 1\n",
      "inherent 1\n",
      "unbalanced 1\n",
      "nature 1\n",
      "detection). 1\n",
      "construct 1\n",
      "likelihood 1\n",
      "generated 1\n",
      "rules[edit] 1\n",
      "databases. 1\n",
      "discovered 1\n",
      "databases 1\n",
      "\"interestingness\".[44] 1\n",
      "identifies, 1\n",
      "learns, 1\n",
      "evolves 1\n",
      "\"rules\" 1\n",
      "store, 1\n",
      "manipulate 1\n",
      "utilization 1\n",
      "relational 1\n",
      "captured 1\n",
      "system. 1\n",
      "singular 1\n",
      "universally 1\n",
      "prediction.[45] 1\n",
      "immune 1\n",
      "Based 1\n",
      "Rakesh 1\n",
      "Tomasz 1\n",
      "Imieliński 1\n",
      "Arun 1\n",
      "Swami 1\n",
      "regularities 1\n",
      "products 1\n",
      "large-scale 1\n",
      "recorded 1\n",
      "point-of-sale 1\n",
      "(POS) 1\n",
      "supermarkets.[46] 1\n",
      "i 1\n",
      ", 1\n",
      "p 1\n",
      "⇒ 1\n",
      "u 1\n",
      "g 1\n",
      "{\\displaystyle 1\n",
      "{onions,potatoes} 1\n",
      "\\}\\Rightarrow 1\n",
      "{burger} 1\n",
      "\\}} 1\n",
      "sales 1\n",
      "supermarket 1\n",
      "indicate 1\n",
      "buys 1\n",
      "onions 1\n",
      "potatoes 1\n",
      "together, 1\n",
      "buy 1\n",
      "hamburger 1\n",
      "meat. 1\n",
      "activities 1\n",
      "promotional 1\n",
      "pricing 1\n",
      "product 1\n",
      "placements. 1\n",
      "basket 1\n",
      "employed 1\n",
      "today 1\n",
      "areas 1\n",
      "usage 1\n",
      "production, 1\n",
      "bioinformatics. 1\n",
      "consider 1\n",
      "transactions. 1\n",
      "(LCS) 1\n",
      "family 1\n",
      "combine 1\n",
      "algorithm, 1\n",
      "seek 1\n",
      "context-dependent 1\n",
      "piecewise 1\n",
      "manner 1\n",
      "predictions.[47] 1\n",
      "(ILP) 1\n",
      "rule-learning 1\n",
      "uniform 1\n",
      "hypotheses. 1\n",
      "encoding 1\n",
      "ILP 1\n",
      "derive 1\n",
      "hypothesized 1\n",
      "entails 1\n",
      "considers 1\n",
      "kind 1\n",
      "hypotheses 1\n",
      "(and 1\n",
      "programming), 1\n",
      "functional 1\n",
      "programs. 1\n",
      "particularly 1\n",
      "useful 1\n",
      "processing. 1\n",
      "Gordon 1\n",
      "laid 1\n",
      "foundation 1\n",
      "setting.[48][49][50] 1\n",
      "implementation 1\n",
      "(Model 1\n",
      "System) 1\n",
      "1981: 1\n",
      "Prolog 1\n",
      "inductively 1\n",
      "inferred 1\n",
      "examples.[51] 1\n",
      "here 1\n",
      "refers 1\n",
      "philosophical 1\n",
      "suggesting 1\n",
      "property 1\n",
      "well-ordered 1\n",
      "Models[edit] 1\n",
      "Performing 1\n",
      "creating 1\n",
      "Various 1\n",
      "researched 1\n",
      "networkSee 1\n",
      "interconnected 1\n",
      "nodes, 1\n",
      "akin 1\n",
      "vast 1\n",
      "circular 1\n",
      "node 1\n",
      "arrow 1\n",
      "(ANNs), 1\n",
      "vaguely 1\n",
      "constitute 1\n",
      "animal 1\n",
      "brains. 1\n",
      "\"learn\" 1\n",
      "task-specific 1\n",
      "rules. 1\n",
      "units 1\n",
      "nodes 1\n",
      "\"artificial 1\n",
      "neurons\", 1\n",
      "loosely 1\n",
      "connection, 1\n",
      "synapses 1\n",
      "brain, 1\n",
      "transmit 1\n",
      "\"signal\", 1\n",
      "it. 1\n",
      "implementations, 1\n",
      "number, 1\n",
      "computed 1\n",
      "sum 1\n",
      "connections 1\n",
      "\"edges\". 1\n",
      "edges 1\n",
      "adjusts 1\n",
      "proceeds. 1\n",
      "decreases 1\n",
      "strength 1\n",
      "connection. 1\n",
      "threshold 1\n",
      "sent 1\n",
      "aggregate 1\n",
      "crosses 1\n",
      "threshold. 1\n",
      "layers. 1\n",
      "transformations 1\n",
      "Signals 1\n",
      "travel 1\n",
      "possibly 1\n",
      "traversing 1\n",
      "times. 1\n",
      "original 1\n",
      "would. 1\n",
      "time, 1\n",
      "attention 1\n",
      "moved 1\n",
      "biology. 1\n",
      "recognition, 1\n",
      "translation, 1\n",
      "filtering, 1\n",
      "video 1\n",
      "diagnosis. 1\n",
      "hidden 1\n",
      "tries 1\n",
      "processes 1\n",
      "light 1\n",
      "sound 1\n",
      "hearing. 1\n",
      "deep 1\n",
      "recognition.[52] 1\n",
      "trees[edit] 1\n",
      "go 1\n",
      "item 1\n",
      "branches) 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conclusions 1\n",
      "item's 1\n",
      "leaves). 1\n",
      "Tree 1\n",
      "discrete 1\n",
      "trees; 1\n",
      "structures, 1\n",
      "leaves 1\n",
      "branches 1\n",
      "conjunctions 1\n",
      "those 1\n",
      "(typically 1\n",
      "numbers) 1\n",
      "trees. 1\n",
      "visually 1\n",
      "describes 1\n",
      "machines[edit] 1\n",
      "(SVMs), 1\n",
      "marked 1\n",
      "belonging 1\n",
      "predicts 1\n",
      "falls 1\n",
      "other.[53] 1\n",
      "non-probabilistic, 1\n",
      "binary, 1\n",
      "classifier, 1\n",
      "although 1\n",
      "Platt 1\n",
      "scaling 1\n",
      "setting. 1\n",
      "SVMs 1\n",
      "efficiently 1\n",
      "trick, 1\n",
      "mapping 1\n",
      "high-dimensional 1\n",
      "spaces. 1\n",
      "Illustration 1\n",
      "analysis[edit] 1\n",
      "estimate 1\n",
      "relationship 1\n",
      "Its 1\n",
      "single 1\n",
      "criterion 1\n",
      "ordinary 1\n",
      "squares. 1\n",
      "latter 1\n",
      "oftentimes 1\n",
      "extended 1\n",
      "regularization 1\n",
      "(mathematics) 1\n",
      "mitigate 1\n",
      "high 1\n",
      "ridge 1\n",
      "go-to 1\n",
      "(e.g. 1\n",
      "trendline 1\n",
      "fitting 1\n",
      "Excel 1\n",
      "[54]), 1\n",
      "(often 1\n",
      "classification) 1\n",
      "introduces 1\n",
      "non-linearity 1\n",
      "taking 1\n",
      "advantage 1\n",
      "trick 1\n",
      "map 1\n",
      "higher 1\n",
      "dimensional 1\n",
      "space. 1\n",
      "simple 1\n",
      "Rain 1\n",
      "activated, 1\n",
      "rain 1\n",
      "grass 1\n",
      "wet. 1\n",
      "network, 1\n",
      "belief 1\n",
      "conditional 1\n",
      "independence 1\n",
      "(DAG). 1\n",
      "diseases 1\n",
      "symptoms. 1\n",
      "symptoms, 1\n",
      "compute 1\n",
      "probabilities 1\n",
      "diseases. 1\n",
      "Efficient 1\n",
      "variables, 1\n",
      "signals 1\n",
      "protein 1\n",
      "sequences, 1\n",
      "networks. 1\n",
      "Generalizations 1\n",
      "uncertainty 1\n",
      "diagrams. 1\n",
      "(GA) 1\n",
      "mimics 1\n",
      "selection, 1\n",
      "mutation 1\n",
      "crossover 1\n",
      "genotypes 1\n",
      "hope 1\n",
      "finding 1\n",
      "solutions 1\n",
      "problem. 1\n",
      "1980s 1\n",
      "1990s.[55][56] 1\n",
      "Conversely, 1\n",
      "evolutionary 1\n",
      "algorithms.[57] 1\n",
      "models[edit] 1\n",
      "lot 1\n",
      "well. 1\n",
      "collect 1\n",
      "large, 1\n",
      "varied 1\n",
      "corpus 1\n",
      "text, 1\n",
      "users 1\n",
      "service. 1\n",
      "Overfitting 1\n",
      "something 1\n",
      "watch 1\n",
      "decentralizes 1\n",
      "process, 1\n",
      "allowing 1\n",
      "maintained 1\n",
      "centralized 1\n",
      "server. 1\n",
      "decentralizing 1\n",
      "devices. 1\n",
      "Gboard 1\n",
      "federated 1\n",
      "train 1\n",
      "query 1\n",
      "mobile 1\n",
      "phones 1\n",
      "searches 1\n",
      "back 1\n",
      "Google.[58] 1\n",
      "Applications[edit] 1\n",
      "including: 1\n",
      "Agriculture 1\n",
      "Anatomy 1\n",
      "websites 1\n",
      "Affective 1\n",
      "Banking 1\n",
      "Bioinformatics 1\n",
      "Brain–machine 1\n",
      "interfaces 1\n",
      "Cheminformatics 1\n",
      "Citizen 1\n",
      "Credit-card 1\n",
      "DNA 1\n",
      "Economics 1\n",
      "Financial 1\n",
      "General 1\n",
      "Handwriting 1\n",
      "Insurance 1\n",
      "Internet 1\n",
      "Linguistics 1\n",
      "perception 1\n",
      "translation 1\n",
      "Marketing 1\n",
      "Medical 1\n",
      "diagnosis 1\n",
      "understanding 1\n",
      "advertising 1\n",
      "Recommender 1\n",
      "Robot 1\n",
      "locomotion 1\n",
      "engines 1\n",
      "Sentiment 1\n",
      "Sequence 1\n",
      "Structural 1\n",
      "monitoring 1\n",
      "Syntactic 1\n",
      "Telecommunication 1\n",
      "Theorem 1\n",
      "Time 1\n",
      "series 1\n",
      "forecasting 1\n",
      "User 1\n",
      "2006, 1\n",
      "media-services 1\n",
      "provider 1\n",
      "held 1\n",
      "\"Netflix 1\n",
      "Prize\" 1\n",
      "competition 1\n",
      "preferences 1\n",
      "existing 1\n",
      "Cinematch 1\n",
      "movie 1\n",
      "10%. 1\n",
      "made 1\n",
      "AT&T 1\n",
      "Labs-Research 1\n",
      "collaboration 1\n",
      "teams 1\n",
      "Chaos 1\n",
      "Pragmatic 1\n",
      "ensemble 1\n",
      "win 1\n",
      "Grand 1\n",
      "Prize 1\n",
      "2009 1\n",
      "$1 1\n",
      "million.[59] 1\n",
      "Shortly 1\n",
      "prize 1\n",
      "awarded, 1\n",
      "realized 1\n",
      "viewers' 1\n",
      "ratings 1\n",
      "indicators 1\n",
      "viewing 1\n",
      "(\"everything 1\n",
      "recommendation\") 1\n",
      "engine 1\n",
      "accordingly.[60] 1\n",
      "2010 1\n",
      "wrote 1\n",
      "Rebellion 1\n",
      "financial 1\n",
      "crisis.[61] 1\n",
      "2012, 1\n",
      "co-founder 1\n",
      "Sun 1\n",
      "Microsystems, 1\n",
      "Khosla, 1\n",
      "predicted 1\n",
      "80% 1\n",
      "doctors' 1\n",
      "jobs 1\n",
      "lost 1\n",
      "next 1\n",
      "decades 1\n",
      "software.[62] 1\n",
      "2014, 1\n",
      "reported 1\n",
      "fine 1\n",
      "paintings, 1\n",
      "revealed 1\n",
      "unrecognized 1\n",
      "artists.[63] 1\n",
      "2019 1\n",
      "published 1\n",
      "learning.[64] 1\n",
      "Limitations[edit] 1\n",
      "Although 1\n",
      "transformative 1\n",
      "fields, 1\n",
      "expected 1\n",
      "results.[65][66][67] 1\n",
      "numerous: 1\n",
      "(suitable) 1\n",
      "badly 1\n",
      "chosen 1\n",
      "wrong 1\n",
      "resources, 1\n",
      "problems.[68] 1\n",
      "2018, 1\n",
      "Uber 1\n",
      "pedestrian, 1\n",
      "collision.[69] 1\n",
      "Attempts 1\n",
      "years 1\n",
      "billions 1\n",
      "investment.[70][71] 1\n",
      "Bias[edit] 1\n",
      "particular 1\n",
      "suffer 1\n",
      "biases. 1\n",
      "current 1\n",
      "customers 1\n",
      "groups 1\n",
      "man-made 1\n",
      "pick 1\n",
      "constitutional 1\n",
      "unconscious 1\n",
      "present 1\n",
      "society.[72] 1\n",
      "shown 1\n",
      "biases.[73][74] 1\n",
      "criminal 1\n",
      "assessment 1\n",
      "biased 1\n",
      "people.[75][76] 1\n",
      "2015, 1\n",
      "photos 1\n",
      "tag 1\n",
      "gorillas,[77] 1\n",
      "2018 1\n",
      "resolved, 1\n",
      "reportedly 1\n",
      "workaround 1\n",
      "remove 1\n",
      "gorilla 1\n",
      "all.[78] 1\n",
      "Similar 1\n",
      "issues 1\n",
      "recognizing 1\n",
      "non-white 1\n",
      "systems.[79] 1\n",
      "2016, 1\n",
      "tested 1\n",
      "Twitter, 1\n",
      "quickly 1\n",
      "picked 1\n",
      "sexist 1\n",
      "language.[80] 1\n",
      "longer 1\n",
      "domains.[81] 1\n",
      "Concern 1\n",
      "propelling 1\n",
      "increasingly 1\n",
      "expressed 1\n",
      "scientists, 1\n",
      "Fei-Fei 1\n",
      "reminds 1\n",
      "engineers 1\n",
      "\"There’s 1\n",
      "nothing 1\n",
      "AI...It’s 1\n",
      "it’s 1\n",
      "and—most 1\n",
      "importantly—it 1\n",
      "impacts 1\n",
      "people. 1\n",
      "powerful 1\n",
      "just 1\n",
      "beginning 1\n",
      "understand, 1\n",
      "profound 1\n",
      "responsibility.”[82] 1\n",
      "assessments[edit] 1\n",
      "validated 1\n",
      "Holdout 1\n",
      "method, 1\n",
      "splits 1\n",
      "(conventionally 1\n",
      "2/3 1\n",
      "1/3 1\n",
      "designation) 1\n",
      "evaluates 1\n",
      "comparison, 1\n",
      "K-fold-cross-validation 1\n",
      "randomly 1\n",
      "partitions 1\n",
      "experiments 1\n",
      "performed 1\n",
      "respectively 1\n",
      "remaining 1\n",
      "K-1 1\n",
      "holdout 1\n",
      "cross-validation 1\n",
      "bootstrap, 1\n",
      "samples 1\n",
      "replacement 1\n",
      "dataset, 1\n",
      "assess 1\n",
      "accuracy.[83] 1\n",
      "accuracy, 1\n",
      "frequently 1\n",
      "sensitivity 1\n",
      "specificity 1\n",
      "(TPR) 1\n",
      "(TNR) 1\n",
      "respectively. 1\n",
      "Similarly, 1\n",
      "(FPR) 1\n",
      "(FNR). 1\n",
      "rates 1\n",
      "ratios 1\n",
      "reveal 1\n",
      "denominators. 1\n",
      "Total 1\n",
      "(TOC) 1\n",
      "model's 1\n",
      "ability. 1\n",
      "denominators 1\n",
      "rates, 1\n",
      "provides 1\n",
      "Receiver 1\n",
      "(ROC) 1\n",
      "ROC's 1\n",
      "Area 1\n",
      "Under 1\n",
      "Curve 1\n",
      "(AUC).[84] 1\n",
      "Ethics[edit] 1\n",
      "poses 1\n",
      "host 1\n",
      "questions. 1\n",
      "exhibit 1\n",
      "upon 1\n",
      "(algorithmic 1\n",
      "bias), 1\n",
      "digitizing 1\n",
      "cultural 1\n",
      "prejudices.[85] 1\n",
      "policies 1\n",
      "duplicating 1\n",
      "scoring 1\n",
      "applicants 1\n",
      "applicants.[86][87] 1\n",
      "Responsible 1\n",
      "documentation 1\n",
      "critical 1\n",
      "biases.[88] 1\n",
      "care. 1\n",
      "concerns 1\n",
      "might 1\n",
      "public's 1\n",
      "interest, 1\n",
      "income 1\n",
      "generating 1\n",
      "machines. 1\n",
      "United 1\n",
      "States 1\n",
      "there 1\n",
      "perpetual 1\n",
      "improving 1\n",
      "care, 1\n",
      "profits. 1\n",
      "patients 1\n",
      "unnecessary 1\n",
      "tests 1\n",
      "medication 1\n",
      "algorithm's 1\n",
      "proprietary 1\n",
      "owners 1\n",
      "hold 1\n",
      "stakes 1\n",
      "in. 1\n",
      "huge 1\n",
      "potential 1\n",
      "great 1\n",
      "diagnose, 1\n",
      "medicate, 1\n",
      "plan 1\n",
      "recovery 1\n",
      "paths 1\n",
      "patients, 1\n",
      "happen 1\n",
      "until 1\n",
      "previously, 1\n",
      "\"greed\" 1\n",
      "addressed.[89] 1\n",
      "Software[edit] 1\n",
      "suites 1\n",
      "containing 1\n",
      "following: 1\n",
      "CNTK 1\n",
      "Deeplearning4j 1\n",
      "ELKI 1\n",
      "Keras 1\n",
      "Caffe 1\n",
      "ML.NET 1\n",
      "Mahout 1\n",
      "Mallet 1\n",
      "mlpack 1\n",
      "MXNet 1\n",
      "Lab 1\n",
      "GNU 1\n",
      "Octave 1\n",
      "OpenNN 1\n",
      "Orange 1\n",
      "scikit-learn 1\n",
      "Shogun 1\n",
      "Spark 1\n",
      "MLlib 1\n",
      "Apache 1\n",
      "SystemML 1\n",
      "TensorFlow 1\n",
      "ROOT 1\n",
      "(TMVA 1\n",
      "ROOT) 1\n",
      "Torch 1\n",
      "PyTorch 1\n",
      "Weka 1\n",
      "MOA 1\n",
      "Yooreeka 1\n",
      "R 1\n",
      "editions[edit] 1\n",
      "KNIME 1\n",
      "RapidMiner 1\n",
      "Amazon 1\n",
      "Angoss 1\n",
      "KnowledgeSTUDIO 1\n",
      "Ayasdi 1\n",
      "Experience 1\n",
      "Prediction 1\n",
      "API 1\n",
      "SPSS 1\n",
      "KXEN 1\n",
      "LIONsolver 1\n",
      "Mathematica 1\n",
      "MATLAB 1\n",
      "Designer 1\n",
      "NeuroSolutions 1\n",
      "Platform 1\n",
      "Cloud 1\n",
      "Service 1\n",
      "RCASE 1\n",
      "SAS 1\n",
      "SequenceL 1\n",
      "Splunk 1\n",
      "STATISTICA 1\n",
      "Journals[edit] 1\n",
      "Conferences[edit] 1\n",
      "also[edit] 1\n",
      "Explanation-based 1\n",
      "Important 1\n",
      "publications 1\n",
      "Predictive 1\n",
      "Quantum 1\n",
      "References[edit] 1\n",
      "\"without 1\n",
      "programmed\" 1\n",
      "attributed 1\n",
      "\"machine 1\n",
      "1959, 1\n",
      "phrase 1\n",
      "verbatim 1\n",
      "publication, 1\n",
      "paraphrase 1\n",
      "appeared 1\n",
      "later. 1\n",
      "Confer 1\n",
      "\"Paraphrasing 1\n",
      "Samuel 1\n",
      "(1959), 1\n",
      "is: 1\n",
      "How 1\n",
      "computers 1\n",
      "programmed?\" 1\n",
      "Koza, 1\n",
      "Bennett, 1\n",
      "Forrest 1\n",
      "Andre, 1\n",
      "David; 1\n",
      "Keane, 1\n",
      "(1996). 1\n",
      "Both 1\n",
      "Topology 1\n",
      "Sizing 1\n",
      "Analog 1\n",
      "Electrical 1\n",
      "Circuits 1\n",
      "Programming. 1\n",
      "'96. 1\n",
      "Dordrecht. 1\n",
      "151–170. 1\n",
      "doi:10.1007/978-94-009-0279-4_9..mw-parser-output 1\n",
      "cite.citation{font-style:inherit}.mw-parser-output 1\n",
      "q{quotes:\"\\\"\"\"\\\"\"\"'\"\"'\"}.mw-parser-output 1\n",
      ".cs1-lock-free 1\n",
      "a{background:url(\"//upload.wikimedia.org/wikipedia/commons/thumb/6/65/Lock-green.svg/9px-Lock-green.svg.png\")no-repeat;background-position:right 1\n",
      ".cs1-lock-limited 1\n",
      "a,.mw-parser-output 1\n",
      ".cs1-lock-registration 1\n",
      "a{background:url(\"//upload.wikimedia.org/wikipedia/commons/thumb/d/d6/Lock-gray-alt-2.svg/9px-Lock-gray-alt-2.svg.png\")no-repeat;background-position:right 1\n",
      ".cs1-lock-subscription 1\n",
      "a{background:url(\"//upload.wikimedia.org/wikipedia/commons/thumb/a/aa/Lock-red-alt-2.svg/9px-Lock-red-alt-2.svg.png\")no-repeat;background-position:right 1\n",
      ".cs1-registration{color:#555}.mw-parser-output 1\n",
      ".cs1-subscription 1\n",
      "span,.mw-parser-output 1\n",
      ".cs1-registration 1\n",
      "span{border-bottom:1px 1\n",
      "dotted;cursor:help}.mw-parser-output 1\n",
      ".cs1-ws-icon 1\n",
      "a{background:url(\"//upload.wikimedia.org/wikipedia/commons/thumb/4/4c/Wikisource-logo.svg/12px-Wikisource-logo.svg.png\")no-repeat;background-position:right 1\n",
      "code.cs1-code{color:inherit;background:inherit;border:inherit;padding:inherit}.mw-parser-output 1\n",
      ".cs1-hidden-error{display:none;font-size:100%}.mw-parser-output 1\n",
      ".cs1-visible-error{font-size:100%}.mw-parser-output 1\n",
      ".cs1-maint{display:none;color:#33aa33;margin-left:0.3em}.mw-parser-output 1\n",
      ".cs1-registration,.mw-parser-output 1\n",
      ".cs1-format{font-size:95%}.mw-parser-output 1\n",
      ".cs1-kern-left,.mw-parser-output 1\n",
      ".cs1-kern-wl-left{padding-left:0.2em}.mw-parser-output 1\n",
      ".cs1-kern-right,.mw-parser-output 1\n",
      ".cs1-kern-wl-right{padding-right:0.2em} 1\n",
      "(2006), 1\n",
      "978-0-387-31073-2 1\n",
      "\"can 1\n",
      "viewed 1\n",
      "facets 1\n",
      "field.\"[2]:vii 1\n",
      "Friedman, 1\n",
      "(1998). 1\n",
      "Statistics: 1\n",
      "What's 1\n",
      "connection?\". 1\n",
      "Statistics. 1\n",
      "29 1\n",
      "3–9. 1\n",
      "(1959). 1\n",
      "\"Some 1\n",
      "Studies 1\n",
      "Game 1\n",
      "Checkers\". 1\n",
      "Development. 1\n",
      "210–229. 1\n",
      "10.1.1.368.2254. 1\n",
      "doi:10.1147/rd.33.0210. 1\n",
      "Mitchell, 1\n",
      "T. 1\n",
      "(1997). 1\n",
      "Hill. 1\n",
      "978-0-07-042807-2. 1\n",
      "Harnad, 1\n",
      "Stevan 1\n",
      "(2008), 1\n",
      "Annotation 1\n",
      "Game: 1\n",
      "On 1\n",
      "(1950) 1\n",
      "Computing, 1\n",
      "Machinery, 1\n",
      "Epstein, 1\n",
      "Robert; 1\n",
      "Peters, 1\n",
      "Grace 1\n",
      "Test 1\n",
      "Sourcebook: 1\n",
      "Philosophical 1\n",
      "Methodological 1\n",
      "Issues 1\n",
      "Thinking 1\n",
      "Computer, 1\n",
      "Kluwer 1\n",
      "R. 1\n",
      "Kohavi 1\n",
      "F. 1\n",
      "Provost, 1\n",
      "\"Glossary 1\n",
      "terms,\" 1\n",
      "vol. 1\n",
      "30, 1\n",
      "no. 1\n",
      "2–3, 1\n",
      "271–274, 1\n",
      "1998. 1\n",
      "Nilsson 1\n",
      "Hill, 1\n",
      "1965. 1\n",
      "R., 1\n",
      "Scene 1\n",
      "Analysis, 1\n",
      "Wiley 1\n",
      "Interscience, 1\n",
      "1973 1\n",
      "Bozinovski 1\n",
      "\"Teaching 1\n",
      "space: 1\n",
      "adaptive 1\n",
      "classification\" 1\n",
      "COINS 1\n",
      "Technical 1\n",
      "No. 1\n",
      "81-28, 1\n",
      "Department, 1\n",
      "Massachusetts 1\n",
      "Amherst, 1\n",
      "https://web.cs.umass.edu/publication/docs/1981/UM-CS-1981-028.pdf 1\n",
      "Sarle, 1\n",
      "Warren 1\n",
      "models\". 1\n",
      "10.1.1.27.699. 1\n",
      "Stuart; 1\n",
      "(2003) 1\n",
      "[1995]. 1\n",
      "978-0137903955. 1\n",
      "Langley, 1\n",
      "Pat 1\n",
      "changing 1\n",
      "82 1\n",
      "275–279. 1\n",
      "doi:10.1007/s10994-011-5242-y. 1\n",
      "Le 1\n",
      "Roux, 1\n",
      "Nicolas; 1\n",
      "Bengio, 1\n",
      "Yoshua; 1\n",
      "Fitzgibbon, 1\n",
      "\"Improving+First+and+Second-Order+Methods+by+Modeling+Uncertainty 1\n",
      "\"Improving 1\n",
      "Second-Order 1\n",
      "Uncertainty\". 1\n",
      "Sra, 1\n",
      "Suvrit; 1\n",
      "Nowozin, 1\n",
      "Sebastian; 1\n",
      "Wright, 1\n",
      "(eds.). 1\n",
      "404. 1\n",
      "Bzdok, 1\n",
      "Danilo; 1\n",
      "Altman, 1\n",
      "Naomi; 1\n",
      "Krzywinski, 1\n",
      "\"Statistics 1\n",
      "versus 1\n",
      "Methods. 1\n",
      "233–234. 1\n",
      "doi:10.1038/nmeth.4642. 1\n",
      "6082636. 1\n",
      "30100822. 1\n",
      "Jordan 1\n",
      "(2014-09-10). 1\n",
      "\"statistics 1\n",
      "reddit. 1\n",
      "2014-10-01. 1\n",
      "Cornell 1\n",
      "Library. 1\n",
      "\"Breiman: 1\n",
      "Modeling: 1\n",
      "Two 1\n",
      "Cultures 1\n",
      "(with 1\n",
      "comments 1\n",
      "rejoinder 1\n",
      "author)\". 1\n",
      "Gareth 1\n",
      "James; 1\n",
      "Daniela 1\n",
      "Witten; 1\n",
      "Hastie; 1\n",
      "vii. 1\n",
      "USA, 1\n",
      "Massachusetts: 1\n",
      "London: 1\n",
      "February 1\n",
      "(Third 1\n",
      "9780136042594. 1\n",
      "9. 1\n",
      "Alex 1\n",
      "Ratner; 1\n",
      "Bach; 1\n",
      "Paroma 1\n",
      "Varma; 1\n",
      "Chris. 1\n",
      "\"Weak 1\n",
      "Supervision: 1\n",
      "Paradigm 1\n",
      "hazyresearch.github.io. 1\n",
      "referencing 1\n",
      "Hazy 1\n",
      "2019-06-06. 1\n",
      "I.; 1\n",
      "Networks\". 1\n",
      "Allen 1\n",
      "B. 1\n",
      "Tucker 1\n",
      "Handbook, 1\n",
      "Second 1\n",
      "Edition 1\n",
      "(Section 1\n",
      "VII: 1\n",
      "Intelligent 1\n",
      "Systems). 1\n",
      "Boca 1\n",
      "Raton, 1\n",
      "Florida: 1\n",
      "Chapman 1\n",
      "Hall/CRC 1\n",
      "Press 1\n",
      "LLC. 1\n",
      "978-1-58488-360-9. 1\n",
      "van 1\n",
      "Otterlo, 1\n",
      "Wiering, 1\n",
      "markov 1\n",
      "processes. 1\n",
      "Adaptation, 1\n",
      "Optimization. 1\n",
      "12. 1\n",
      "3–42. 1\n",
      "doi:10.1007/978-3-642-27645-3_1. 1\n",
      "978-3-642-27644-6. 1\n",
      "(1982). 1\n",
      "secondary 1\n",
      "reinforcement\" 1\n",
      ". 1\n",
      "Trappl, 1\n",
      "Research: 1\n",
      "Sixth 1\n",
      "European 1\n",
      "Meeting 1\n",
      "North 1\n",
      "Holland. 1\n",
      "397–402. 1\n",
      "978-0-444-86488-8. 1\n",
      "Stevo 1\n",
      "(2014) 1\n",
      "\"Modeling 1\n",
      "cognition-emotion 1\n",
      "since 1\n",
      "1981.\" 1\n",
      "Procedia 1\n",
      "255-263 1\n",
      "\"Self-learning 1\n",
      "agents: 1\n",
      "judgment.\" 1\n",
      "32(6) 1\n",
      "637-667. 1\n",
      "Bengio; 1\n",
      "Courville; 1\n",
      "Vincent 1\n",
      "\"Representation 1\n",
      "Review 1\n",
      "Perspectives\". 1\n",
      "35 1\n",
      "(8): 1\n",
      "1798–1828. 1\n",
      "arXiv:1206.5538. 1\n",
      "doi:10.1109/tpami.2013.50. 1\n",
      "23787338. 1\n",
      "Nathan 1\n",
      "Srebro; 1\n",
      "Rennie; 1\n",
      "Tommi 1\n",
      "Jaakkola 1\n",
      "Maximum-Margin 1\n",
      "Matrix 1\n",
      "Factorization. 1\n",
      "NIPS. 1\n",
      "Coates, 1\n",
      "Adam; 1\n",
      "Honglak; 1\n",
      "Ng, 1\n",
      "single-layer 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int'l 1\n",
      "Conf. 1\n",
      "(AISTATS). 1\n",
      "Csurka, 1\n",
      "Gabriella; 1\n",
      "Dance, 1\n",
      "C.; 1\n",
      "Fan, 1\n",
      "Lixin; 1\n",
      "Willamowski, 1\n",
      "Jutta; 1\n",
      "Bray, 1\n",
      "Cédric 1\n",
      "Visual 1\n",
      "categorization 1\n",
      "bags 1\n",
      "keypoints 1\n",
      "ECCV 1\n",
      "Vision. 1\n",
      "Daniel 1\n",
      "Jurafsky; 1\n",
      "Processing. 1\n",
      "Pearson 1\n",
      "Education 1\n",
      "International. 1\n",
      "145–146. 1\n",
      "Lu, 1\n",
      "Haiping; 1\n",
      "Plataniotis, 1\n",
      "K.N.; 1\n",
      "Venetsanopoulos, 1\n",
      "A.N. 1\n",
      "Subspace 1\n",
      "Tensor 1\n",
      "Data\" 1\n",
      "Recognition. 1\n",
      "44 1\n",
      "(7): 1\n",
      "1540–1551. 1\n",
      "doi:10.1016/j.patcog.2011.01.004. 1\n",
      "Yoshua 1\n",
      "Bengio 1\n",
      "Architectures 1\n",
      "Now 1\n",
      "Inc. 1\n",
      "1–3. 1\n",
      "978-1-60198-294-0. 1\n",
      "Tillmann, 1\n",
      "(2015). 1\n",
      "\"On 1\n",
      "Intractability 1\n",
      "Exact 1\n",
      "Approximate 1\n",
      "Dictionary 1\n",
      "Letters. 1\n",
      "45–49. 1\n",
      "arXiv:1405.6664. 1\n",
      "Bibcode:2015ISPL...22...45T. 1\n",
      "doi:10.1109/LSP.2014.2345761. 1\n",
      "Aharon, 1\n",
      "M, 1\n",
      "M 1\n",
      "Elad, 1\n",
      "Bruckstein. 1\n",
      "2006. 1\n",
      "\"K-SVD: 1\n",
      "Designing 1\n",
      "Overcomplete 1\n",
      "Dictionaries 1\n",
      "Representation.\" 1\n",
      "Processing, 1\n",
      "54 1\n",
      "4311–4322 1\n",
      "Zimek, 1\n",
      "Arthur; 1\n",
      "Schubert, 1\n",
      "Erich 1\n",
      "(2017), 1\n",
      "\"Outlier 1\n",
      "Detection\", 1\n",
      "Encyclopedia 1\n",
      "Systems, 1\n",
      "1–5, 1\n",
      "doi:10.1007/978-1-4899-7993-3_80719-1, 1\n",
      "9781489979933 1\n",
      "Hodge, 1\n",
      "Austin, 1\n",
      "Outlier 1\n",
      "Detection 1\n",
      "Methodologies\" 1\n",
      "85–126. 1\n",
      "10.1.1.318.4023. 1\n",
      "doi:10.1007/s10462-004-4304-y. 1\n",
      "Dokas, 1\n",
      "Paul; 1\n",
      "Ertoz, 1\n",
      "Levent; 1\n",
      "Vipin; 1\n",
      "Lazarevic, 1\n",
      "Aleksandar; 1\n",
      "Srivastava, 1\n",
      "Jaideep; 1\n",
      "Tan, 1\n",
      "Pang-Ning 1\n",
      "(2002). 1\n",
      "detection\" 1\n",
      "NSF 1\n",
      "Next 1\n",
      "Generation 1\n",
      "Mining. 1\n",
      "Chandola, 1\n",
      "Banerjee, 1\n",
      "A.; 1\n",
      "\"Anomaly 1\n",
      "detection: 1\n",
      "survey\". 1\n",
      "Surveys. 1\n",
      "41 1\n",
      "1–58. 1\n",
      "doi:10.1145/1541880.1541882. 1\n",
      "Gregory 1\n",
      "(1991), 1\n",
      "Discovery, 1\n",
      "presentation 1\n",
      "Gregory; 1\n",
      "Frawley, 1\n",
      "William 1\n",
      "eds., 1\n",
      "Discovery 1\n",
      "Databases, 1\n",
      "AAAI/MIT 1\n",
      "MA. 1\n",
      "Bassel, 1\n",
      "George 1\n",
      "W.; 1\n",
      "Glaab, 1\n",
      "Enrico; 1\n",
      "Marquez, 1\n",
      "Julietta; 1\n",
      "Holdsworth, 1\n",
      "Bacardit, 1\n",
      "Jaume 1\n",
      "(2011-09-01). 1\n",
      "\"Functional 1\n",
      "Construction 1\n",
      "Arabidopsis 1\n",
      "Rule-Based 1\n",
      "Large-Scale 1\n",
      "Sets\". 1\n",
      "Plant 1\n",
      "Cell. 1\n",
      "23 1\n",
      "(9): 1\n",
      "3101–3116. 1\n",
      "doi:10.1105/tpc.111.088153. 1\n",
      "1532-298X. 1\n",
      "3203449. 1\n",
      "21896882. 1\n",
      "Imieliński, 1\n",
      "T.; 1\n",
      "Swami, 1\n",
      "(1993). 1\n",
      "\"Mining 1\n",
      "databases\". 1\n",
      "1993 1\n",
      "Management 1\n",
      "'93. 1\n",
      "207. 1\n",
      "10.1.1.40.6984. 1\n",
      "doi:10.1145/170035.170072. 1\n",
      "978-0897915922. 1\n",
      "Urbanowicz, 1\n",
      "Ryan 1\n",
      "Moore, 1\n",
      "(2009-09-22). 1\n",
      "\"Learning 1\n",
      "Classifier 1\n",
      "Systems: 1\n",
      "Complete 1\n",
      "Introduction, 1\n",
      "Review, 1\n",
      "Roadmap\". 1\n",
      "Evolution 1\n",
      "Applications. 1\n",
      "2009: 1\n",
      "1–25. 1\n",
      "doi:10.1155/2009/736398. 1\n",
      "1687-6229. 1\n",
      "G.D. 1\n",
      "Automatic 1\n",
      "PhD 1\n",
      "thesis, 1\n",
      "Edinburgh, 1\n",
      "1970. 1\n",
      "theories 1\n",
      "192, 1\n",
      "Yale 1\n",
      "University, 1\n",
      "Department 1\n",
      "Science, 1\n",
      "Reprinted 1\n",
      "J.-L. 1\n",
      "Lassez, 1\n",
      "(Eds.), 1\n",
      "Logic, 1\n",
      "1991, 1\n",
      "199–254. 1\n",
      "(1983). 1\n",
      "debugging. 1\n",
      "Mass: 1\n",
      "0-262-19218-7 1\n",
      "system.\" 1\n",
      "7th 1\n",
      "intelligence-Volume 1\n",
      "Kaufmann 1\n",
      "Honglak 1\n",
      "Roger 1\n",
      "Grosse, 1\n",
      "Rajesh 1\n",
      "Ranganath, 1\n",
      "Ng. 1\n",
      "\"Convolutional 1\n",
      "Belief 1\n",
      "Scalable 1\n",
      "Representations\" 1\n",
      "26th 1\n",
      "Annual 1\n",
      "2009. 1\n",
      "Cortes, 1\n",
      "Corinna; 1\n",
      "Vapnik, 1\n",
      "Vladimir 1\n",
      "\"Support-vector 1\n",
      "networks\". 1\n",
      "20 1\n",
      "273–297. 1\n",
      "doi:10.1007/BF00994018. 1\n",
      "Stevenson, 1\n",
      "Christopher. 1\n",
      "\"Tutorial: 1\n",
      "Polynomial 1\n",
      "Excel\". 1\n",
      "facultystaff.richmond.edu. 1\n",
      "January 1\n",
      "Goldberg, 1\n",
      "E.; 1\n",
      "Holland, 1\n",
      "(1988). 1\n",
      "\"Genetic 1\n",
      "95–99. 1\n",
      "doi:10.1007/bf00113892. 1\n",
      "Michie, 1\n",
      "Spiegelhalter, 1\n",
      "Taylor, 1\n",
      "Classification\". 1\n",
      "Ellis 1\n",
      "Horwood 1\n",
      "Series 1\n",
      "Bibcode:1994mlns.book.....M. 1\n",
      "Zhang, 1\n",
      "Jun; 1\n",
      "Zhan, 1\n",
      "Zhi-hui; 1\n",
      "Lin, 1\n",
      "Ying; 1\n",
      "Chen, 1\n",
      "Ni; 1\n",
      "Gong, 1\n",
      "Yue-jiao; 1\n",
      "Zhong, 1\n",
      "Jing-hui; 1\n",
      "Chung, 1\n",
      "Henry 1\n",
      "S.H.; 1\n",
      "Yun; 1\n",
      "Shi, 1\n",
      "Yu-hui 1\n",
      "\"Evolutionary 1\n",
      "Meets 1\n",
      "Survey\". 1\n",
      "Magazine. 1\n",
      "68–75. 1\n",
      "doi:10.1109/mci.2011.942584. 1\n",
      "\"Federated 1\n",
      "Collaborative 1\n",
      "Centralized 1\n",
      "Data\". 1\n",
      "Blog. 1\n",
      "2019-06-08. 1\n",
      "\"BelKor 1\n",
      "Home 1\n",
      "Page\" 1\n",
      "research.att.com 1\n",
      "Blog: 1\n",
      "Recommendations: 1\n",
      "Beyond 1\n",
      "stars 1\n",
      "(Part 1\n",
      "1)\". 1\n",
      "2012-04-06. 1\n",
      "Scott 1\n",
      "Patterson 1\n",
      "(13 1\n",
      "July 1\n",
      "2010). 1\n",
      "\"Letting 1\n",
      "Decide\". 1\n",
      "24 1\n",
      "June 1\n",
      "2018. 1\n",
      "Khosla 1\n",
      "(January 1\n",
      "10, 1\n",
      "2012). 1\n",
      "\"Do 1\n",
      "We 1\n",
      "Need 1\n",
      "Doctors 1\n",
      "Algorithms?\". 1\n",
      "Crunch. 1\n",
      "Studied 1\n",
      "Fine 1\n",
      "Paintings, 1\n",
      "Saw 1\n",
      "Things 1\n",
      "Historians 1\n",
      "Had 1\n",
      "Never 1\n",
      "Noticed, 1\n",
      "Physics 1\n",
      "ArXiv 1\n",
      "blog 1\n",
      "Vincent, 1\n",
      "(2019-04-10). 1\n",
      "AI-generated 1\n",
      "textbook 1\n",
      "writers 1\n",
      "actually 1\n",
      "at\". 1\n",
      "2019-05-05. 1\n",
      "Often 1\n",
      "Fail 1\n",
      "Learn: 1\n",
      "QuickTake 1\n",
      "Q&A\". 1\n",
      "Bloomberg.com. 1\n",
      "2016-11-10. 1\n",
      "2017-04-10. 1\n",
      "Wave 1\n",
      "Corporate 1\n",
      "Is 1\n",
      "Doomed 1\n",
      "Fail\". 1\n",
      "Harvard 1\n",
      "Business 1\n",
      "2017-04-18. 1\n",
      "A.I. 1\n",
      "euphoria 1\n",
      "doomed 1\n",
      "VentureBeat. 1\n",
      "2016-09-18. 1\n",
      "\"9 1\n",
      "why 1\n",
      "your 1\n",
      "project 1\n",
      "www.kdnuggets.com. 1\n",
      "Uber's 1\n",
      "pedestrian\". 1\n",
      "Economist. 1\n",
      "\"IBM's 1\n",
      "recommended 1\n",
      "'unsafe 1\n",
      "incorrect' 1\n",
      "cancer 1\n",
      "treatments 1\n",
      "STAT\". 1\n",
      "STAT. 1\n",
      "2018-07-25. 1\n",
      "Hernandez, 1\n",
      "Daniela; 1\n",
      "Greenwald, 1\n",
      "Ted 1\n",
      "(2018-08-11). 1\n",
      "\"IBM 1\n",
      "Has 1\n",
      "Dilemma\". 1\n",
      "0099-9660. 1\n",
      "Garcia, 1\n",
      "Megan 1\n",
      "(2016). 1\n",
      "\"Racist 1\n",
      "Machine\". 1\n",
      "Policy 1\n",
      "33 1\n",
      "111–117. 1\n",
      "doi:10.1215/07402775-3813015. 1\n",
      "0740-2775. 1\n",
      "Caliskan, 1\n",
      "Aylin; 1\n",
      "Bryson, 1\n",
      "Joanna 1\n",
      "(2017-04-14). 1\n",
      "\"Semantics 1\n",
      "derived 1\n",
      "automatically 1\n",
      "biases\". 1\n",
      "356 1\n",
      "(6334): 1\n",
      "183–186. 1\n",
      "arXiv:1608.07187. 1\n",
      "Bibcode:2017Sci...356..183C. 1\n",
      "doi:10.1126/science.aal4230. 1\n",
      "0036-8075. 1\n",
      "28408601. 1\n",
      "Wang, 1\n",
      "Xinan; 1\n",
      "Dasgupta, 1\n",
      "Sanjoy 1\n",
      "(2016), 1\n",
      "Sugiyama, 1\n",
      "Luxburg, 1\n",
      "U. 1\n",
      "Guyon, 1\n",
      "\"An 1\n",
      "L1 1\n",
      "nearest 1\n",
      "neighbor 1\n",
      "monotonic 1\n",
      "embedding\" 1\n",
      "(PDF), 1\n",
      "Advances 1\n",
      "29, 1\n",
      "Curran 1\n",
      "Associates, 1\n",
      "983–991, 1\n",
      "retrieved 1\n",
      "2018-08-20 1\n",
      "Julia 1\n",
      "Angwin; 1\n",
      "Jeff 1\n",
      "Larson; 1\n",
      "Lauren 1\n",
      "Kirchner; 1\n",
      "Surya 1\n",
      "Mattu 1\n",
      "(2016-05-23). 1\n",
      "Bias\". 1\n",
      "ProPublica. 1\n",
      "Helps 1\n",
      "Send 1\n",
      "You 1\n",
      "Prison\". 1\n",
      "apologises 1\n",
      "blunder\". 1\n",
      "BBC 1\n",
      "News. 1\n",
      "2015-07-01. 1\n",
      "'fixed' 1\n",
      "removing 1\n",
      "image-labeling 1\n",
      "tech\". 1\n",
      "Intelligence's 1\n",
      "White 1\n",
      "Guy 1\n",
      "Problem\". 1\n",
      "Metz, 1\n",
      "Rachel. 1\n",
      "Microsoft's 1\n",
      "teen 1\n",
      "chatbot, 1\n",
      "Tay, 1\n",
      "lots 1\n",
      "awful 1\n",
      "things 1\n",
      "online\". 1\n",
      "Simonite, 1\n",
      "Tom. 1\n",
      "\"Microsoft 1\n",
      "says 1\n",
      "illustrates 1\n",
      "isn't 1\n",
      "adaptable 1\n",
      "enough 1\n",
      "help 1\n",
      "businesses\". 1\n",
      "Hempel, 1\n",
      "Jessi 1\n",
      "(2018-11-13). 1\n",
      "\"Fei-Fei 1\n",
      "Li's 1\n",
      "Make 1\n",
      "Better 1\n",
      "Humanity\". 1\n",
      "Wired. 1\n",
      "1059-1028. 1\n",
      "2019-02-17. 1\n",
      "Kohavi, 1\n",
      "Ron 1\n",
      "Study 1\n",
      "Cross-Validation 1\n",
      "Bootstrap 1\n",
      "Accuracy 1\n",
      "Estimation 1\n",
      "Selection\" 1\n",
      "Joint 1\n",
      "Pontius, 1\n",
      "Gilmore; 1\n",
      "Si, 1\n",
      "Kangping 1\n",
      "(2014). 1\n",
      "total 1\n",
      "operating 1\n",
      "thresholds\". 1\n",
      "Geographical 1\n",
      "28 1\n",
      "570–583. 1\n",
      "doi:10.1080/13658816.2013.862623. 1\n",
      "Bostrom, 1\n",
      "Nick 1\n",
      "Intelligence\" 1\n",
      "April 1\n",
      "2016. 1\n",
      "Edionwe, 1\n",
      "Tolulope. 1\n",
      "fight 1\n",
      "algorithms\". 1\n",
      "Jeffries, 1\n",
      "Adrianne. 1\n",
      "because 1\n",
      "internet 1\n",
      "racist\". 1\n",
      "(August 1\n",
      "24, 1\n",
      "2016). 1\n",
      "\"Language 1\n",
      "corpora\". 1\n",
      "Freedom 1\n",
      "Tinker. 1\n",
      "Char, 1\n",
      "S.; 1\n",
      "Shah, 1\n",
      "Magnus, 1\n",
      "\"Implementing 1\n",
      "Health 1\n",
      "Care—Addressing 1\n",
      "Ethical 1\n",
      "Challenges\". 1\n",
      "England 1\n",
      "Medicine. 1\n",
      "378 1\n",
      "981–983. 1\n",
      "doi:10.1056/nejmp1714229. 1\n",
      "5962261. 1\n",
      "29539284. 1\n",
      "reading[edit] 1\n",
      ".mw-parser-output 1\n",
      ".refbegin{font-size:90%;margin-bottom:0.5em}.mw-parser-output 1\n",
      ".refbegin-hanging-indents>ul{list-style-type:none;margin-left:0}.mw-parser-output 1\n",
      ".refbegin-hanging-indents>ul>li,.mw-parser-output 1\n",
      ".refbegin-hanging-indents>dl>dd{margin-left:0;padding-left:3.2em;text-indent:-3.2em;list-style:none}.mw-parser-output 1\n",
      ".refbegin-100{font-size:100%} 1\n",
      "Nils 1\n",
      "Nilsson, 1\n",
      "Hastie, 1\n",
      "Friedman 1\n",
      "(2001). 1\n",
      "Elements 1\n",
      "0-387-95284-5. 1\n",
      "Pedro 1\n",
      "Domingos 1\n",
      "(September 1\n",
      "2015), 1\n",
      "Master 1\n",
      "Algorithm, 1\n",
      "Basic 1\n",
      "Books, 1\n",
      "978-0-465-06570-7 1\n",
      "Ian 1\n",
      "Witten 1\n",
      "Eibe 1\n",
      "Frank 1\n",
      "Mining: 1\n",
      "Practical 1\n",
      "Kaufmann, 1\n",
      "664pp., 1\n",
      "978-0-12-374856-0. 1\n",
      "Alpaydin 1\n",
      "MacKay. 1\n",
      "Cambridge: 1\n",
      "Cambridge 1\n",
      "2003. 1\n",
      "0-521-64298-1 1\n",
      "Richard 1\n",
      "O. 1\n",
      "E. 1\n",
      "Hart, 1\n",
      "Stork 1\n",
      "edition), 1\n",
      "Wiley, 1\n",
      "0-471-05669-3. 1\n",
      "Bishop 1\n",
      "Recognition, 1\n",
      "Oxford 1\n",
      "0-19-853864-2. 1\n",
      "Russell 1\n",
      "– 1\n",
      "Approach. 1\n",
      "Pearson, 1\n",
      "9789332543515. 1\n",
      "Machine, 1\n",
      "IRE 1\n",
      "Convention 1\n",
      "Record, 1\n",
      "Section 1\n",
      "Part 1\n",
      "2, 1\n",
      "pp., 1\n",
      "56–62, 1\n",
      "1957. 1\n",
      "privately 1\n",
      "circulated 1\n",
      "1956 1\n",
      "Dartmouth 1\n",
      "Summer 1\n",
      "links[edit] 1\n",
      "media 1\n",
      "Society 1\n",
      "mloss 1\n",
      "software. 1\n",
      "Crash 1\n",
      "Course 1\n",
      "Google. 1\n",
      "course 1\n",
      "TensorFlow. 1\n",
      "vteComputer 1\n",
      "scienceNote: 1\n",
      "template 1\n",
      "roughly 1\n",
      "2012 1\n",
      "System.Hardware 1\n",
      "Printed 1\n",
      "Peripheral 1\n",
      "Very 1\n",
      "Large 1\n",
      "Scale 1\n",
      "Integration 1\n",
      "Chip 1\n",
      "(SoCs) 1\n",
      "Energy 1\n",
      "consumption 1\n",
      "(Green 1\n",
      "computing) 1\n",
      "automation 1\n",
      "acceleration 1\n",
      "systemsorganization 1\n",
      "Embedded 1\n",
      "Real-time 1\n",
      "Dependability 1\n",
      "protocol 1\n",
      "scheduler 1\n",
      "service 1\n",
      "organization 1\n",
      "Interpreter 1\n",
      "Middleware 1\n",
      "notationsand 1\n",
      "Compiler 1\n",
      "Domain-specific 1\n",
      "framework 1\n",
      "configuration 1\n",
      "repository 1\n",
      "Requirements 1\n",
      "construction 1\n",
      "deployment 1\n",
      "maintenance 1\n",
      "Open-source 1\n",
      "Automata 1\n",
      "Logic 1\n",
      "Semantics 1\n",
      "Randomized 1\n",
      "geometry 1\n",
      "Mathematicsof 1\n",
      "Discrete 1\n",
      "Probability 1\n",
      "Numerical 1\n",
      "Informationsystems 1\n",
      "storage 1\n",
      "Geographic 1\n",
      "Multimedia 1\n",
      "platform 1\n",
      "Wide 1\n",
      "Cryptography 1\n",
      "services 1\n",
      "Intrusion 1\n",
      "Application 1\n",
      "Human–computerinteraction 1\n",
      "Ubiquitous 1\n",
      "Visualization 1\n",
      "Accessibility 1\n",
      "Concurrency 1\n",
      "Concurrent 1\n",
      "Parallel 1\n",
      "Multithreading 1\n",
      "Multiprocessing 1\n",
      "Artificialintelligence 1\n",
      "planning 1\n",
      "scheduling 1\n",
      "methodology 1\n",
      "Control 1\n",
      "Philosophy 1\n",
      "Multi-task 1\n",
      "Cross-validation 1\n",
      "Animation 1\n",
      "Rendering 1\n",
      "manipulation 1\n",
      "unit 1\n",
      "Mixed 1\n",
      "compression 1\n",
      "Solid 1\n",
      "Appliedcomputing 1\n",
      "E-commerce 1\n",
      "physics 1\n",
      "chemistry 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "biology 1\n",
      "publishing 1\n",
      "Cyberwarfare 1\n",
      "voting 1\n",
      "Video 1\n",
      "Word 1\n",
      "Operations 1\n",
      "Educational 1\n",
      "technology 1\n",
      "Document 1\n",
      "Book 1\n",
      "Category 1\n",
      "WikiProject 1\n",
      "\"https://en.wikipedia.org/w/index.php?title=Machine_learning&oldid=927399027\" 1\n",
      "Categories: 1\n",
      "learningCyberneticsLearningHidden 1\n",
      "categories: 1\n",
      "Articles 1\n",
      "short 1\n",
      "descriptionWikipedia 1\n",
      "clarification 1\n",
      "2018Commons 1\n",
      "link 1\n",
      "Wikidata 1\n",
      "menu 1\n",
      "Personal 1\n",
      "Not 1\n",
      "logged 1\n",
      "inTalkContributionsCreate 1\n",
      "accountLog 1\n",
      "Namespaces 1\n",
      "ArticleTalk 1\n",
      "Variants 1\n",
      "Views 1\n",
      "ReadEditView 1\n",
      "More 1\n",
      "pageContentsFeatured 1\n",
      "contentCurrent 1\n",
      "eventsRandom 1\n",
      "articleDonate 1\n",
      "WikipediaWikipedia 1\n",
      "HelpAbout 1\n",
      "WikipediaCommunity 1\n",
      "portalRecent 1\n",
      "changesContact 1\n",
      "Tools 1\n",
      "What 1\n",
      "hereRelated 1\n",
      "changesUpload 1\n",
      "fileSpecial 1\n",
      "pagesPermanent 1\n",
      "linkPage 1\n",
      "informationWikidata 1\n",
      "itemCite 1\n",
      "projects 1\n",
      "CommonsWikiversity 1\n",
      "Print/export 1\n",
      "Create 1\n",
      "bookDownload 1\n",
      "PDFPrintable 1\n",
      "version 1\n",
      "Languages 1\n",
      "العربيةঅসমীয়াAzərbaycancaবাংলাBân-lâm-gúБългарскиCatalàČeštinaCymraegDanskDeutschEestiΕλληνικάEspañolEuskaraفارسیFrançais한국어Հայերենहिन्दीBahasa 1\n",
      "IndonesiaÍslenskaItalianoעבריתಕನ್ನಡLatviešuLietuviųMagyarМакедонскиമലയാളംमराठीBahasa 1\n",
      "MelayuМонголNederlands日本語NorskNorsk 1\n",
      "nynorskOccitanଓଡ଼ିଆPolskiPortuguêsRomânăРусскийᱥᱟᱱᱛᱟᱲᱤShqipSimple 1\n",
      "EnglishSlovenščinaСрпски 1\n",
      "srpskiSrpskohrvatski 1\n",
      "српскохрватскиSuomiSvenskaTagalogதமிழ்తెలుగుไทยTürkçeУкраїнськаئۇيغۇرچە 1\n",
      "UyghurcheTiếng 1\n",
      "ViệtVõro粵語中文 1\n",
      "Edit 1\n",
      "edited 1\n",
      "2019, 1\n",
      "07:22 1\n",
      "(UTC). 1\n",
      "Text 1\n",
      "available 1\n",
      "Creative 1\n",
      "Attribution-ShareAlike 1\n",
      "License; 1\n",
      "apply. 1\n",
      "site, 1\n",
      "you 1\n",
      "agree 1\n",
      "Terms 1\n",
      "Use 1\n",
      "Policy. 1\n",
      "Wikipedia® 1\n",
      "registered 1\n",
      "trademark 1\n",
      "non-profit 1\n",
      "organization. 1\n",
      "policy 1\n",
      "About 1\n",
      "Disclaimers 1\n",
      "Contact 1\n",
      "Developers 1\n",
      "Cookie 1\n",
      "statement 1\n",
      "Mobile 1\n",
      "view 1\n",
      "(RLQ=window.RLQ||[]).push(function(){mw.config.set({\"wgPageParseReport\":{\"limitreport\":{\"cputime\":\"1.316\",\"walltime\":\"1.644\",\"ppvisitednodes\":{\"value\":7281,\"limit\":1000000},\"ppgeneratednodes\":{\"value\":0,\"limit\":1500000},\"postexpandincludesize\":{\"value\":215719,\"limit\":2097152},\"templateargumentsize\":{\"value\":10610,\"limit\":2097152},\"expansiondepth\":{\"value\":16,\"limit\":40},\"expensivefunctioncount\":{\"value\":8,\"limit\":500},\"unstrip-depth\":{\"value\":1,\"limit\":20},\"unstrip-size\":{\"value\":250096,\"limit\":5000000},\"entityaccesscount\":{\"value\":7,\"limit\":400},\"timingprofile\":[\"100.00% 1\n",
      "1341.741 1\n",
      "-total\",\" 1\n",
      "55.06% 1\n",
      "738.705 1\n",
      "Template:Reflist\",\" 1\n",
      "21.38% 1\n",
      "286.860 1\n",
      "21 1\n",
      "Template:Cite_journal\",\" 1\n",
      "9.32% 1\n",
      "125.035 1\n",
      "Template:Cite_conference\",\" 1\n",
      "8.38% 1\n",
      "112.477 1\n",
      "Template:Refn\",\" 1\n",
      "7.79% 1\n",
      "104.546 1\n",
      "Template:ISBN\",\" 1\n",
      "7.23% 1\n",
      "97.007 1\n",
      "Template:Cite_book\",\" 1\n",
      "6.32% 1\n",
      "84.740 1\n",
      "Template:Cite_web\",\" 1\n",
      "5.07% 1\n",
      "68.057 1\n",
      "Template:Clarify\",\" 1\n",
      "4.72% 1\n",
      "63.374 1\n",
      "Template:Cite_news\"]},\"scribunto\":{\"limitreport-timeusage\":{\"value\":\"0.671\",\"limit\":\"10.000\"},\"limitreport-memusage\":{\"value\":8337402,\"limit\":52428800}},\"cachereport\":{\"origin\":\"mw1249\",\"timestamp\":\"20191122072244\",\"ttl\":2592000,\"transientcontent\":false}}});}); 1\n",
      "{\"@context\":\"https:\\/\\/schema.org\",\"@type\":\"Article\",\"name\":\"Machine 1\n",
      "learning\",\"url\":\"https:\\/\\/en.wikipedia.org\\/wiki\\/Machine_learning\",\"sameAs\":\"http:\\/\\/www.wikidata.org\\/entity\\/Q2539\",\"mainEntity\":\"http:\\/\\/www.wikidata.org\\/entity\\/Q2539\",\"author\":{\"@type\":\"Organization\",\"name\":\"Contributors 1\n",
      "projects\"},\"publisher\":{\"@type\":\"Organization\",\"name\":\"Wikimedia 1\n",
      "Inc.\",\"logo\":{\"@type\":\"ImageObject\",\"url\":\"https:\\/\\/www.wikimedia.org\\/static\\/images\\/wmf-hor-googpub.png\"}},\"datePublished\":\"2003-05-25T06:03:17Z\",\"dateModified\":\"2019-11-22T07:22:38Z\",\"image\":\"https:\\/\\/upload.wikimedia.org\\/wikipedia\\/commons\\/f\\/fe\\/Kernel_Machine.svg\",\"headline\":\"branch 1\n",
      "science, 1\n",
      "studies 1\n",
      "architectures 1\n",
      "facts\"} 1\n",
      "(RLQ=window.RLQ||[]).push(function(){mw.config.set({\"wgBackendResponseTime\":101,\"wgHostname\":\"mw1266\"});}); 1\n"
     ]
    }
   ],
   "source": [
    "#3. Count the number of unique words in each page and their frequencies.\n",
    "li=[]\n",
    "\n",
    "c=simple_get('https://en.wikipedia.org/wiki/Machine_learning')\n",
    "html=BeautifulSoup(c,'html.parser')\n",
    "def freq(str): \n",
    "  \n",
    "    # break the string into list of words  \n",
    "    str = str.split()          \n",
    "    str2 = [] \n",
    "  \n",
    "    # loop till string values present in list str \n",
    "    for i in str:              \n",
    "  \n",
    "        # checking for the duplicacy \n",
    "        if i not in str2: \n",
    "  \n",
    "            # insert value in str2 \n",
    "            str2.append(i)  \n",
    "              \n",
    "    for i in range(0, len(str2)): \n",
    "        \n",
    "        if str.count(str2[i])<=1   :\n",
    "        \n",
    "        # count the frequency of each word(present  \n",
    "        # in str2) in str and print \n",
    "            print(str2[i],(str.count(str2[i])))\n",
    "\n",
    "freq(html.body.text)      \n",
    "\n",
    "   \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Get all the images in each page to you device.\n",
    "def down(site):\n",
    "    \n",
    "    response = requests.get(site)\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    img_tags = soup.find_all('img')\n",
    "    try:\n",
    "        urls = [img['src'] for img in img_tags]\n",
    "    \n",
    "        for url in urls:\n",
    "            filename = re.search(r'/([\\w_-]+[.](jpg|gif|png))$', url)\n",
    "            if  filename is not None:\n",
    "           \n",
    "                with open(filename.group(1), 'wb') as f:\n",
    "                    if 'http' not in url:\n",
    "            # sometimes an image source can be relative \n",
    "            # if it is provide the base url which also happens \n",
    "            # to be the site variable atm. \n",
    "                        url = '{}{}'.format(site, url)\n",
    "                    response = requests.get(url)\n",
    "                    f.write(response.content)\n",
    "    except :\n",
    "        pass\n",
    "        \n",
    "li=get_links(\"https://en.wikipedia.org/wiki/Machine_learning\", tag='a', attrbute='href', start = '^http')\n",
    "li2=[]\n",
    "   \n",
    "for x in range(100):\n",
    "    li2.append(get_links(li[x],tag='a', attrbute='href', start = '^http'))\n",
    "\n",
    "li2=list(chain(*li2))\n",
    "                    \n",
    "for i in range(len(li2)):\n",
    "    down(li2[i])\n",
    "\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Machine ', 'Machine '),\n",
       " ('From Wikipedia', 'From Wikipedia'),\n",
       " ('Jump ', 'Jump '),\n",
       " ('Jump ', 'Jump '),\n",
       " ('For ', 'For '),\n",
       " ('Machine Learning ', 'Machine Learning '),\n",
       " ('Statistical ', 'Statistical '),\n",
       " ('Scientific ', 'Scientific '),\n",
       " ('Machine ', 'Machine '),\n",
       " ('Problems\\nClassification\\nClustering\\nRegression\\nAnomaly ',\n",
       "  'Problems\\nClassification\\nClustering\\nRegression\\nAnomaly '),\n",
       " ('Auto', 'Auto'),\n",
       " ('Association ', 'Association '),\n",
       " ('Reinforcement ', 'Reinforcement '),\n",
       " ('Structured ', 'Structured '),\n",
       " ('Feature ', 'Feature '),\n",
       " ('Feature ', 'Feature '),\n",
       " ('Online ', 'Online '),\n",
       " ('Semi', 'Semi'),\n",
       " ('Unsupervised ', 'Unsupervised '),\n",
       " ('Learning ', 'Learning '),\n",
       " ('Grammar ', 'Grammar '),\n",
       " ('Supervised ', 'Supervised '),\n",
       " ('Decision ', 'Decision '),\n",
       " ('Ensembles\\nBagging\\nBoosting\\nRandom ',\n",
       "  'Ensembles\\nBagging\\nBoosting\\nRandom '),\n",
       " ('Linear ', 'Linear '),\n",
       " ('Naive Bayes\\nArtificial ', 'Naive Bayes\\nArtificial '),\n",
       " ('Logistic ', 'Logistic '),\n",
       " ('Perceptron\\nRelevance ', 'Perceptron\\nRelevance '),\n",
       " ('Support ', 'Support '),\n",
       " ('Clustering\\n', 'Clustering\\n'),\n",
       " ('Hierarchical\\n', 'Hierarchical\\n'),\n",
       " ('Expectation', 'Expectation'),\n",
       " ('Mean', 'Mean'),\n",
       " ('Dimensionality ', 'Dimensionality '),\n",
       " ('Factor ', 'Factor '),\n",
       " ('Structured ', 'Structured '),\n",
       " ('Graphical ', 'Graphical '),\n",
       " ('Bayes ', 'Bayes '),\n",
       " ('Conditional ', 'Conditional '),\n",
       " ('Hidden Markov\\n\\n\\nAnomaly ', 'Hidden Markov\\n\\n\\nAnomaly '),\n",
       " ('Local ', 'Local '),\n",
       " ('Artificial ', 'Artificial '),\n",
       " ('Autoencoder\\nDeep ', 'Autoencoder\\nDeep '),\n",
       " ('DeepDream\\nMultilayer ', 'DeepDream\\nMultilayer '),\n",
       " ('Restricted Boltzmann ', 'Restricted Boltzmann '),\n",
       " ('Convolutional ', 'Convolutional '),\n",
       " ('Net\\n\\n\\nReinforcement ', 'Net\\n\\n\\nReinforcement '),\n",
       " ('Temporal ', 'Temporal '),\n",
       " ('Theory\\nBias', 'Theory\\nBias'),\n",
       " ('Computational ', 'Computational '),\n",
       " ('Empirical ', 'Empirical '),\n",
       " ('Occam ', 'Occam '),\n",
       " ('Statistical ', 'Statistical '),\n",
       " ('Machine', 'Machine'),\n",
       " ('Neur', 'Neur'),\n",
       " ('ArXiv', 'ArXiv'),\n",
       " ('Glossary ', 'Glossary '),\n",
       " ('Glossary ', 'Glossary '),\n",
       " ('Related ', 'Related '),\n",
       " ('List ', 'List '),\n",
       " ('Outline ', 'Outline '),\n",
       " ('Machine ', 'Machine '),\n",
       " ('Machine ', 'Machine '),\n",
       " ('Machine ', 'Machine '),\n",
       " ('In ', 'In '),\n",
       " ('Contents\\n\\n', 'Contents\\n\\n'),\n",
       " ('Overview\\n\\n', 'Overview\\n\\n'),\n",
       " ('Machine ', 'Machine '),\n",
       " ('History ', 'History '),\n",
       " ('Relation ', 'Relation '),\n",
       " ('Relation ', 'Relation '),\n",
       " ('Relation ', 'Relation '),\n",
       " ('Theory\\n', 'Theory\\n'),\n",
       " ('Approaches\\n\\n', 'Approaches\\n\\n'),\n",
       " ('Types ', 'Types '),\n",
       " ('Supervised ', 'Supervised '),\n",
       " ('Unsupervised ', 'Unsupervised '),\n",
       " ('Reinforcement ', 'Reinforcement '),\n",
       " ('Self ', 'Self '),\n",
       " ('Feature ', 'Feature '),\n",
       " ('Sparse ', 'Sparse '),\n",
       " ('Anomaly ', 'Anomaly '),\n",
       " ('Association ', 'Association '),\n",
       " ('Models\\n\\n', 'Models\\n\\n'),\n",
       " ('Artificial ', 'Artificial '),\n",
       " ('Decision ', 'Decision '),\n",
       " ('Support ', 'Support '),\n",
       " ('Regression ', 'Regression '),\n",
       " ('Bayesian ', 'Bayesian '),\n",
       " ('Genetic ', 'Genetic '),\n",
       " ('Training ', 'Training '),\n",
       " ('Federated ', 'Federated '),\n",
       " ('Applications\\n', 'Applications\\n'),\n",
       " ('Limitations\\n\\n', 'Limitations\\n\\n'),\n",
       " ('Bias\\n\\n\\n', 'Bias\\n\\n\\n'),\n",
       " ('Model ', 'Model '),\n",
       " ('Ethics\\n', 'Ethics\\n'),\n",
       " ('Software\\n\\n', 'Software\\n\\n'),\n",
       " ('Free ', 'Free '),\n",
       " ('Proprietary ', 'Proprietary '),\n",
       " ('Proprietary ', 'Proprietary '),\n",
       " ('Journals\\n', 'Journals\\n'),\n",
       " ('Conferences\\n', 'Conferences\\n'),\n",
       " ('See ', 'See '),\n",
       " ('References\\n', 'References\\n'),\n",
       " ('Further ', 'Further '),\n",
       " ('External ', 'External '),\n",
       " ('Overview', 'Overview'),\n",
       " ('The ', 'The '),\n",
       " ('Arthur Samuel', 'Arthur Samuel'),\n",
       " ('Tom ', 'Tom '),\n",
       " ('This ', 'This '),\n",
       " ('Alan Turing', 'Alan Turing'),\n",
       " ('Computing Machinery ', 'Computing Machinery '),\n",
       " ('Intelligence', 'Intelligence'),\n",
       " ('Can ', 'Can '),\n",
       " ('Can ', 'Can '),\n",
       " ('In Turing', 'In Turing'),\n",
       " ('Machine ', 'Machine '),\n",
       " ('Machine ', 'Machine '),\n",
       " ('Semi', 'Semi'),\n",
       " ('Classification ', 'Classification '),\n",
       " ('Boolean ', 'Boolean '),\n",
       " ('In ', 'In '),\n",
       " ('Active ', 'Active '),\n",
       " ('Other ', 'Other '),\n",
       " ('History ', 'History '),\n",
       " ('See ', 'See '),\n",
       " ('Timeline ', 'Timeline '),\n",
       " ('Arthur Samuel', 'Arthur Samuel'),\n",
       " ('American ', 'American '),\n",
       " ('Machine Learning', 'Machine Learning'),\n",
       " ('Nilsson', 'Nilsson'),\n",
       " ('Learning Machines', 'Learning Machines'),\n",
       " ('The ', 'The '),\n",
       " ('Duda ', 'Duda '),\n",
       " ('Hart ', 'Hart '),\n",
       " ('In ', 'In '),\n",
       " ('As ', 'As '),\n",
       " ('Probabilistic ', 'Probabilistic '),\n",
       " ('However', 'However'),\n",
       " ('By ', 'By '),\n",
       " ('Work ', 'Work '),\n",
       " ('Neural ', 'Neural '),\n",
       " ('Hopfield', 'Hopfield'),\n",
       " ('Rumelhart ', 'Rumelhart '),\n",
       " ('Hinton', 'Hinton'),\n",
       " ('Machine ', 'Machine '),\n",
       " ('It ', 'It '),\n",
       " ('Internet', 'Internet'),\n",
       " ('Relation ', 'Relation '),\n",
       " ('Machine ', 'Machine '),\n",
       " ('Relation ', 'Relation '),\n",
       " ('Machine ', 'Machine '),\n",
       " ('Relation ', 'Relation '),\n",
       " ('Machine ', 'Machine '),\n",
       " ('According ', 'According '),\n",
       " ('Michael ', 'Michael '),\n",
       " ('He ', 'He '),\n",
       " ('Leo Breiman ', 'Leo Breiman '),\n",
       " ('Random ', 'Random '),\n",
       " ('Some ', 'Some '),\n",
       " ('Theory', 'Theory'),\n",
       " ('Main ', 'Main '),\n",
       " ('Computational ', 'Computational '),\n",
       " ('Statistical ', 'Statistical '),\n",
       " ('Generalization ', 'Generalization '),\n",
       " ('The ', 'The '),\n",
       " ('For ', 'For '),\n",
       " ('In ', 'In '),\n",
       " ('Approaches', 'Approaches'),\n",
       " ('Types ', 'Types '),\n",
       " ('The ', 'The '),\n",
       " ('Supervised ', 'Supervised '),\n",
       " ('Main ', 'Main '),\n",
       " ('Supervised ', 'Supervised '),\n",
       " ('Supervised ', 'Supervised '),\n",
       " ('The ', 'The '),\n",
       " ('In ', 'In '),\n",
       " ('An ', 'An '),\n",
       " ('Supervised ', 'Supervised '),\n",
       " ('Classification ', 'Classification '),\n",
       " ('In ', 'In '),\n",
       " ('Unsupervised ', 'Unsupervised '),\n",
       " ('Main ', 'Main '),\n",
       " ('Unsupervised ', 'Unsupervised '),\n",
       " ('See ', 'See '),\n",
       " ('Cluster ', 'Cluster '),\n",
       " ('Unsupervised ', 'Unsupervised '),\n",
       " ('Cluster ', 'Cluster '),\n",
       " ('Reinforcement ', 'Reinforcement '),\n",
       " ('Main ', 'Main '),\n",
       " ('Reinforcement ', 'Reinforcement '),\n",
       " ('Reinforcement ', 'Reinforcement '),\n",
       " ('Markov Decision Process ', 'Markov Decision Process '),\n",
       " ('Reinforcement ', 'Reinforcement '),\n",
       " ('Self ', 'Self '),\n",
       " ('Self ', 'Self '),\n",
       " ('Crossbar Adaptive Array ', 'Crossbar Adaptive Array '),\n",
       " ('It ', 'It '),\n",
       " ('The ', 'The '),\n",
       " ('In ', 'In '),\n",
       " ('Receive ', 'Receive '),\n",
       " ('Compute ', 'Compute '),\n",
       " ('Update ', 'Update '),\n",
       " ('It ', 'It '),\n",
       " ('Feature ', 'Feature '),\n",
       " ('Main ', 'Main '),\n",
       " ('Feature ', 'Feature '),\n",
       " ('Several ', 'Several '),\n",
       " ('Classic ', 'Classic '),\n",
       " ('Feature ', 'Feature '),\n",
       " ('Examples ', 'Examples '),\n",
       " ('Manifold ', 'Manifold '),\n",
       " ('Deep ', 'Deep '),\n",
       " ('Feature ', 'Feature '),\n",
       " ('Sparse ', 'Sparse '),\n",
       " ('Main ', 'Main '),\n",
       " ('Sparse ', 'Sparse '),\n",
       " ('Sparse ', 'Sparse '),\n",
       " ('Anomaly ', 'Anomaly '),\n",
       " ('Main ', 'Main '),\n",
       " ('Anomaly ', 'Anomaly '),\n",
       " ('In ', 'In '),\n",
       " ('Typically', 'Typically'),\n",
       " ('In ', 'In '),\n",
       " ('Three ', 'Three '),\n",
       " ('Unsupervised ', 'Unsupervised '),\n",
       " ('Association ', 'Association '),\n",
       " ('Main ', 'Main '),\n",
       " ('Association ', 'Association '),\n",
       " ('See ', 'See '),\n",
       " ('Inductive ', 'Inductive '),\n",
       " ('Association ', 'Association '),\n",
       " ('Rule', 'Rule'),\n",
       " ('Rule', 'Rule'),\n",
       " ('Based ', 'Based '),\n",
       " ('Rakesh Agrawal', 'Rakesh Agrawal'),\n",
       " ('Tomasz Imieli', 'Tomasz Imieli'),\n",
       " ('Arun Swami ', 'Arun Swami '),\n",
       " ('For ', 'For '),\n",
       " ('Rightarrow ', 'Rightarrow '),\n",
       " ('Web ', 'Web '),\n",
       " ('Learning ', 'Learning '),\n",
       " ('Inductive ', 'Inductive '),\n",
       " ('Inductive ', 'Inductive '),\n",
       " ('Plotkin ', 'Plotkin '),\n",
       " ('Ehud Shapiro ', 'Ehud Shapiro '),\n",
       " ('Shapiro ', 'Shapiro '),\n",
       " ('Model Inference System', 'Model Inference System'),\n",
       " ('Prolog ', 'Prolog '),\n",
       " ('The ', 'The '),\n",
       " ('Models', 'Models'),\n",
       " ('Performing ', 'Performing '),\n",
       " ('Artificial ', 'Artificial '),\n",
       " ('Main ', 'Main '),\n",
       " ('Artificial ', 'Artificial '),\n",
       " ('See ', 'See '),\n",
       " ('Deep ', 'Deep '),\n",
       " ('An ', 'An '),\n",
       " ('Artificial ', 'Artificial '),\n",
       " ('Ns', 'Ns'),\n",
       " ('An ', 'An '),\n",
       " ('The ', 'The '),\n",
       " ('Deep ', 'Deep '),\n",
       " ('Decision ', 'Decision '),\n",
       " ('Main ', 'Main '),\n",
       " ('Decision ', 'Decision '),\n",
       " ('Decision ', 'Decision '),\n",
       " ('Support ', 'Support '),\n",
       " ('Main ', 'Main '),\n",
       " ('Support ', 'Support '),\n",
       " ('Support ', 'Support '),\n",
       " ('Ms', 'Ms'),\n",
       " ('An ', 'An '),\n",
       " ('Platt ', 'Platt '),\n",
       " ('Ms ', 'Ms '),\n",
       " ('Illustration ', 'Illustration '),\n",
       " ('Regression ', 'Regression '),\n",
       " ('Main ', 'Main '),\n",
       " ('Regression ', 'Regression '),\n",
       " ('Regression ', 'Regression '),\n",
       " ('Microsoft Excel ', 'Microsoft Excel '),\n",
       " ('Logistic ', 'Logistic '),\n",
       " ('Bayesian ', 'Bayesian '),\n",
       " ('Main ', 'Main '),\n",
       " ('Bayesian ', 'Bayesian '),\n",
       " ('Bayesian ', 'Bayesian '),\n",
       " ('Bayesian ', 'Bayesian '),\n",
       " ('Bayesian ', 'Bayesian '),\n",
       " ('Bayesian ', 'Bayesian '),\n",
       " ('Bayesian ', 'Bayesian '),\n",
       " ('Genetic ', 'Genetic '),\n",
       " ('Main ', 'Main '),\n",
       " ('Genetic ', 'Genetic '),\n",
       " ('Conversely', 'Conversely'),\n",
       " ('Training ', 'Training '),\n",
       " ('Usually', 'Usually'),\n",
       " ('Federated ', 'Federated '),\n",
       " ('Main ', 'Main '),\n",
       " ('Federated ', 'Federated '),\n",
       " ('Federated ', 'Federated '),\n",
       " ('Gboard ', 'Gboard '),\n",
       " ('Google', 'Google'),\n",
       " ('Applications', 'Applications'),\n",
       " ('There ', 'There '),\n",
       " ('Agriculture\\nAnatomy\\nAdaptive ', 'Agriculture\\nAnatomy\\nAdaptive '),\n",
       " ('Affective ', 'Affective '),\n",
       " ('Banking\\nBioinformatics\\nBrain', 'Banking\\nBioinformatics\\nBrain'),\n",
       " ('Cheminformatics\\nCitizen Science\\nComputer Networks\\nComputer ',\n",
       "  'Cheminformatics\\nCitizen Science\\nComputer Networks\\nComputer '),\n",
       " ('Credit', 'Credit'),\n",
       " ('Data ', 'Data '),\n",
       " ('Economics\\nFinancial ', 'Economics\\nFinancial '),\n",
       " ('General ', 'General '),\n",
       " ('Handwriting ', 'Handwriting '),\n",
       " ('Information ', 'Information '),\n",
       " ('Insurance\\nInternet ', 'Insurance\\nInternet '),\n",
       " ('Linguistics\\nMachine ', 'Linguistics\\nMachine '),\n",
       " ('Machine ', 'Machine '),\n",
       " ('Machine ', 'Machine '),\n",
       " ('Marketing\\nMedical ', 'Marketing\\nMedical '),\n",
       " ('Natural ', 'Natural '),\n",
       " ('Natural ', 'Natural '),\n",
       " ('Online ', 'Online '),\n",
       " ('Optimization\\nRecommender ', 'Optimization\\nRecommender '),\n",
       " ('Robot ', 'Robot '),\n",
       " ('Search ', 'Search '),\n",
       " ('Sentiment ', 'Sentiment '),\n",
       " ('Sequence ', 'Sequence '),\n",
       " ('Software ', 'Software '),\n",
       " ('Speech ', 'Speech '),\n",
       " ('Structural ', 'Structural '),\n",
       " ('Syntactic ', 'Syntactic '),\n",
       " ('Telecommunication\\nTheorem ', 'Telecommunication\\nTheorem '),\n",
       " ('Time ', 'Time '),\n",
       " ('User ', 'User '),\n",
       " ('In ', 'In '),\n",
       " ('Netflix ', 'Netflix '),\n",
       " ('Netflix Prize', 'Netflix Prize'),\n",
       " ('Cinematch ', 'Cinematch '),\n",
       " ('Labs', 'Labs'),\n",
       " ('Research ', 'Research '),\n",
       " ('Big Chaos ', 'Big Chaos '),\n",
       " ('Pragmatic Theory ', 'Pragmatic Theory '),\n",
       " ('Grand Prize ', 'Grand Prize '),\n",
       " ('Shortly ', 'Shortly '),\n",
       " ('Netflix ', 'Netflix '),\n",
       " ('In ', 'In '),\n",
       " ('The Wall Street Journal ', 'The Wall Street Journal '),\n",
       " ('Rebellion Research ', 'Rebellion Research '),\n",
       " ('In ', 'In '),\n",
       " ('Sun Microsystems', 'Sun Microsystems'),\n",
       " ('Vinod Khosla', 'Vinod Khosla'),\n",
       " ('In ', 'In '),\n",
       " ('In ', 'In '),\n",
       " ('Springer Nature ', 'Springer Nature '),\n",
       " ('Limitations', 'Limitations'),\n",
       " ('Although ', 'Although '),\n",
       " ('Reasons ', 'Reasons '),\n",
       " ('In ', 'In '),\n",
       " ('Uber ', 'Uber '),\n",
       " ('Attempts ', 'Attempts '),\n",
       " ('Watson ', 'Watson '),\n",
       " ('Bias', 'Bias'),\n",
       " ('Main ', 'Main '),\n",
       " ('Algorithmic ', 'Algorithmic '),\n",
       " ('Machine ', 'Machine '),\n",
       " ('Language ', 'Language '),\n",
       " ('Machine ', 'Machine '),\n",
       " ('In ', 'In '),\n",
       " ('Google ', 'Google '),\n",
       " ('Google ', 'Google '),\n",
       " ('Similar ', 'Similar '),\n",
       " ('In ', 'In '),\n",
       " ('Microsoft ', 'Microsoft '),\n",
       " ('Twitter', 'Twitter'),\n",
       " ('Because ', 'Because '),\n",
       " ('Concern ', 'Concern '),\n",
       " ('Fei', 'Fei'),\n",
       " ('Fei Li', 'Fei Li'),\n",
       " ('There', 'There'),\n",
       " ('It', 'It'),\n",
       " ('Model ', 'Model '),\n",
       " ('Classification ', 'Classification '),\n",
       " ('Holdout ', 'Holdout '),\n",
       " ('In ', 'In '),\n",
       " ('True Positive Rate ', 'True Positive Rate '),\n",
       " ('True Negative Rate ', 'True Negative Rate '),\n",
       " ('False Positive Rate ', 'False Positive Rate '),\n",
       " ('False Negative Rate ', 'False Negative Rate '),\n",
       " ('Total Operating Characteristic ', 'Total Operating Characteristic '),\n",
       " ('Receiver Operating Characteristic ', 'Receiver Operating Characteristic '),\n",
       " ('Area Under ', 'Area Under '),\n",
       " ('Curve ', 'Curve '),\n",
       " ('Ethics', 'Ethics'),\n",
       " ('Machine ', 'Machine '),\n",
       " ('For ', 'For '),\n",
       " ('Responsible ', 'Responsible '),\n",
       " ('Because ', 'Because '),\n",
       " ('Other ', 'Other '),\n",
       " ('United States ', 'United States '),\n",
       " ('Software', 'Software'),\n",
       " ('Software ', 'Software '),\n",
       " ('Free ', 'Free '),\n",
       " ('Deeplearning', 'Deeplearning'),\n",
       " ('Keras\\nCaffe\\n', 'Keras\\nCaffe\\n'),\n",
       " ('Mahout\\nMallet\\n', 'Mahout\\nMallet\\n'),\n",
       " ('Net\\nNeural Lab\\n', 'Net\\nNeural Lab\\n'),\n",
       " ('Octave\\nOpen', 'Octave\\nOpen'),\n",
       " ('Orange\\n', 'Orange\\n'),\n",
       " ('Shogun\\nSpark ', 'Shogun\\nSpark '),\n",
       " ('Llib\\nApache System', 'Llib\\nApache System'),\n",
       " ('TensorFlow\\n', 'TensorFlow\\n'),\n",
       " ('Torch ', 'Torch '),\n",
       " ('PyTorch\\nWeka ', 'PyTorch\\nWeka '),\n",
       " ('Yooreeka\\n', 'Yooreeka\\n'),\n",
       " ('Proprietary ', 'Proprietary '),\n",
       " ('RapidMiner\\n\\nProprietary ', 'RapidMiner\\n\\nProprietary '),\n",
       " ('Amazon Machine Learning\\nAngoss Knowledge',\n",
       "  'Amazon Machine Learning\\nAngoss Knowledge'),\n",
       " ('Azure Machine Learning\\nAyasdi\\n', 'Azure Machine Learning\\nAyasdi\\n'),\n",
       " ('Data Science Experience\\nGoogle Prediction ',\n",
       "  'Data Science Experience\\nGoogle Prediction '),\n",
       " ('Modeler\\n', 'Modeler\\n'),\n",
       " ('Modeler\\n', 'Modeler\\n'),\n",
       " ('Nsolver\\nMathematica\\n', 'Nsolver\\nMathematica\\n'),\n",
       " ('Microsoft Azure Machine Learning\\nNeural Designer\\nNeuroSolutions\\nOracle Data Mining\\nOracle ',\n",
       "  'Microsoft Azure Machine Learning\\nNeural Designer\\nNeuroSolutions\\nOracle Data Mining\\nOracle '),\n",
       " ('Platform Cloud Service\\n', 'Platform Cloud Service\\n'),\n",
       " ('Enterprise Miner\\nSequence', 'Enterprise Miner\\nSequence'),\n",
       " ('Splunk\\n', 'Splunk\\n'),\n",
       " ('Data Miner\\n\\nJournals', 'Data Miner\\n\\nJournals'),\n",
       " ('Journal ', 'Journal '),\n",
       " ('Machine Learning Research\\nMachine Learning\\nNature Machine Intelligence\\nNeural Computation\\nConferences',\n",
       "  'Machine Learning Research\\nMachine Learning\\nNature Machine Intelligence\\nNeural Computation\\nConferences'),\n",
       " ('Conference ', 'Conference '),\n",
       " ('Neural Information Processing Systems\\nInternational Conference ',\n",
       "  'Neural Information Processing Systems\\nInternational Conference '),\n",
       " ('Machine Learning\\nSee ', 'Machine Learning\\nSee '),\n",
       " ('Automated ', 'Automated '),\n",
       " ('Big ', 'Big '),\n",
       " ('Explanation', 'Explanation'),\n",
       " ('Important ', 'Important '),\n",
       " ('List ', 'List '),\n",
       " ('Predictive ', 'Predictive '),\n",
       " ('Quantum ', 'Quantum '),\n",
       " ('Machine', 'Machine'),\n",
       " ('References', 'References'),\n",
       " ('The ', 'The '),\n",
       " ('Arthur Samuel', 'Arthur Samuel'),\n",
       " ('Paraphrasing Arthur Samuel ', 'Paraphrasing Arthur Samuel '),\n",
       " ('How ', 'How '),\n",
       " ('Koza', 'Koza'),\n",
       " ('John ', 'John '),\n",
       " ('Bennett', 'Bennett'),\n",
       " ('Forrest ', 'Forrest '),\n",
       " ('Andre', 'Andre'),\n",
       " ('David', 'David'),\n",
       " ('Keane', 'Keane'),\n",
       " ('Martin ', 'Martin '),\n",
       " ('Design ', 'Design '),\n",
       " ('Both ', 'Both '),\n",
       " ('Topology ', 'Topology '),\n",
       " ('Sizing ', 'Sizing '),\n",
       " ('Analog Electrical Circuits Using Genetic Programming',\n",
       "  'Analog Electrical Circuits Using Genetic Programming'),\n",
       " ('Intelligence ', 'Intelligence '),\n",
       " ('Design ', 'Design '),\n",
       " ('Dordrecht', 'Dordrecht'),\n",
       " ('Lock', 'Lock'),\n",
       " ('Lock', 'Lock'),\n",
       " ('Lock', 'Lock'),\n",
       " ('Lock', 'Lock'),\n",
       " ('Lock', 'Lock'),\n",
       " ('Lock', 'Lock'),\n",
       " ('Wikisource', 'Wikisource'),\n",
       " ('Wikisource', 'Wikisource'),\n",
       " ('Bishop', 'Bishop'),\n",
       " ('Pattern Recognition ', 'Pattern Recognition '),\n",
       " ('Machine Learning', 'Machine Learning'),\n",
       " ('Springer', 'Springer'),\n",
       " ('Machine ', 'Machine '),\n",
       " ('Friedman', 'Friedman'),\n",
       " ('Jerome ', 'Jerome '),\n",
       " ('Data Mining ', 'Data Mining '),\n",
       " ('Statistics', 'Statistics'),\n",
       " ('What', 'What'),\n",
       " ('Science ', 'Science '),\n",
       " ('Statistics', 'Statistics'),\n",
       " ('Samuel', 'Samuel'),\n",
       " ('Arthur ', 'Arthur '),\n",
       " ('Some Studies ', 'Some Studies '),\n",
       " ('Machine Learning Using ', 'Machine Learning Using '),\n",
       " ('Game ', 'Game '),\n",
       " ('Checkers', 'Checkers'),\n",
       " ('Journal ', 'Journal '),\n",
       " ('Research ', 'Research '),\n",
       " ('Development', 'Development'),\n",
       " ('Seer', 'Seer'),\n",
       " ('Mitchell', 'Mitchell'),\n",
       " ('Learning', 'Learning'),\n",
       " ('Graw Hill', 'Graw Hill'),\n",
       " ('Harnad', 'Harnad'),\n",
       " ('Stevan ', 'Stevan '),\n",
       " ('The Annotation Game', 'The Annotation Game'),\n",
       " ('On Turing ', 'On Turing '),\n",
       " ('Computing', 'Computing'),\n",
       " ('Machinery', 'Machinery'),\n",
       " ('Intelligence', 'Intelligence'),\n",
       " ('Epstein', 'Epstein'),\n",
       " ('Robert', 'Robert'),\n",
       " ('Peters', 'Peters'),\n",
       " ('Grace ', 'Grace '),\n",
       " ('The Turing Test Sourcebook', 'The Turing Test Sourcebook'),\n",
       " ('Philosophical ', 'Philosophical '),\n",
       " ('Methodological Issues ', 'Methodological Issues '),\n",
       " ('Quest ', 'Quest '),\n",
       " ('Thinking Computer', 'Thinking Computer'),\n",
       " ('Kluwer\\n\\n', 'Kluwer\\n\\n'),\n",
       " ('Glossary ', 'Glossary '),\n",
       " ('Machine Learning', 'Machine Learning'),\n",
       " ('Nilsson ', 'Nilsson '),\n",
       " ('Machines', 'Machines'),\n",
       " ('McGraw Hill', 'McGraw Hill'),\n",
       " ('Duda', 'Duda'),\n",
       " ('Hart ', 'Hart '),\n",
       " ('Recognition ', 'Recognition '),\n",
       " ('Scene Analysis', 'Scene Analysis'),\n",
       " ('Wiley Interscience', 'Wiley Interscience'),\n",
       " ('Teaching ', 'Teaching '),\n",
       " ('Technical Report No', 'Technical Report No'),\n",
       " ('Computer ', 'Computer '),\n",
       " ('Information Science Department', 'Information Science Department'),\n",
       " ('University ', 'University '),\n",
       " ('Massachusetts ', 'Massachusetts '),\n",
       " ('Amherst', 'Amherst'),\n",
       " ('Sarle', 'Sarle'),\n",
       " ('Warren ', 'Warren '),\n",
       " ('Neural Networks ', 'Neural Networks '),\n",
       " ('Seer', 'Seer'),\n",
       " ('Russell', 'Russell'),\n",
       " ('Stuart', 'Stuart'),\n",
       " ('Norvig', 'Norvig'),\n",
       " ('Peter ', 'Peter '),\n",
       " ('Intelligence', 'Intelligence'),\n",
       " ('Modern Approach ', 'Modern Approach '),\n",
       " ('Hall', 'Hall'),\n",
       " ('Langley', 'Langley'),\n",
       " ('Pat ', 'Pat '),\n",
       " ('The ', 'The '),\n",
       " ('Learning', 'Learning'),\n",
       " ('Le Roux', 'Le Roux'),\n",
       " ('Nicolas', 'Nicolas'),\n",
       " ('Bengio', 'Bengio'),\n",
       " ('Yoshua', 'Yoshua'),\n",
       " ('Fitzgibbon', 'Fitzgibbon'),\n",
       " ('Andrew ', 'Andrew '),\n",
       " ('Improving', 'Improving'),\n",
       " ('First', 'First'),\n",
       " ('Second', 'Second'),\n",
       " ('Order', 'Order'),\n",
       " ('Methods', 'Methods'),\n",
       " ('Modeling', 'Modeling'),\n",
       " ('Uncertainty ', 'Uncertainty '),\n",
       " ('Improving First ', 'Improving First '),\n",
       " ('Second', 'Second'),\n",
       " ('Order Methods ', 'Order Methods '),\n",
       " ('Modeling Uncertainty', 'Modeling Uncertainty'),\n",
       " ('In Sra', 'In Sra'),\n",
       " ('Suvrit', 'Suvrit'),\n",
       " ('Nowozin', 'Nowozin'),\n",
       " ('Sebastian', 'Sebastian'),\n",
       " ('Wright', 'Wright'),\n",
       " ('Stephen ', 'Stephen '),\n",
       " ('Machine Learning', 'Machine Learning'),\n",
       " ('Press', 'Press'),\n",
       " ('Bzdok', 'Bzdok'),\n",
       " ('Danilo', 'Danilo'),\n",
       " ('Altman', 'Altman'),\n",
       " ('Naomi', 'Naomi'),\n",
       " ('Krzywinski', 'Krzywinski'),\n",
       " ('Martin ', 'Martin '),\n",
       " ('Statistics ', 'Statistics '),\n",
       " ('Machine Learning', 'Machine Learning'),\n",
       " ('Methods', 'Methods'),\n",
       " ('Michael ', 'Michael '),\n",
       " ('Cornell University Library', 'Cornell University Library'),\n",
       " ('Breiman', 'Breiman'),\n",
       " ('Statistical Modeling', 'Statistical Modeling'),\n",
       " ('The Two Cultures ', 'The Two Cultures '),\n",
       " ('August ', 'August '),\n",
       " ('Gareth James', 'Gareth James'),\n",
       " ('Daniela Witten', 'Daniela Witten'),\n",
       " ('Trevor Hastie', 'Trevor Hastie'),\n",
       " ('Robert Tibshirani ', 'Robert Tibshirani '),\n",
       " ('Introduction ', 'Introduction '),\n",
       " ('Statistical Learning', 'Statistical Learning'),\n",
       " ('Mohri', 'Mohri'),\n",
       " ('Mehryar', 'Mehryar'),\n",
       " ('Rostamizadeh', 'Rostamizadeh'),\n",
       " ('Afshin', 'Afshin'),\n",
       " ('Talwalkar', 'Talwalkar'),\n",
       " ('Ameet ', 'Ameet '),\n",
       " ('Machine Learning', 'Machine Learning'),\n",
       " ('Massachusetts', 'Massachusetts'),\n",
       " ('Press', 'Press'),\n",
       " ('Alpaydin', 'Alpaydin'),\n",
       " ('Ethem ', 'Ethem '),\n",
       " ('Machine Learning', 'Machine Learning'),\n",
       " ('The ', 'The '),\n",
       " ('Press', 'Press'),\n",
       " ('February ', 'February '),\n",
       " ('Russell', 'Russell'),\n",
       " ('Stuart ', 'Stuart '),\n",
       " ('Norvig', 'Norvig'),\n",
       " ('Peter ', 'Peter '),\n",
       " ('Intelligence', 'Intelligence'),\n",
       " ('Modern Approach ', 'Modern Approach '),\n",
       " ('Third ', 'Third '),\n",
       " ('Hall', 'Hall'),\n",
       " ('Mohri', 'Mohri'),\n",
       " ('Mehryar', 'Mehryar'),\n",
       " ('Rostamizadeh', 'Rostamizadeh'),\n",
       " ('Afshin', 'Afshin'),\n",
       " ('Talwalkar', 'Talwalkar'),\n",
       " ('Ameet ', 'Ameet '),\n",
       " ('Machine Learning', 'Machine Learning'),\n",
       " ('Press', 'Press'),\n",
       " ('Alpaydin', 'Alpaydin'),\n",
       " ('Ethem ', 'Ethem '),\n",
       " ('Machine Learning', 'Machine Learning'),\n",
       " ('Press', 'Press'),\n",
       " ('Alex Ratner', 'Alex Ratner'),\n",
       " ('Stephen Bach', 'Stephen Bach'),\n",
       " ('Paroma Varma', 'Paroma Varma'),\n",
       " ('Chris', 'Chris'),\n",
       " ('Weak Supervision', 'Weak Supervision'),\n",
       " ('The New Programming Paradigm ', 'The New Programming Paradigm '),\n",
       " ('Machine Learning', 'Machine Learning'),\n",
       " ('Hazy Research', 'Hazy Research'),\n",
       " ('Jordan', 'Jordan'),\n",
       " ('Michael ', 'Michael '),\n",
       " ('Bishop', 'Bishop'),\n",
       " ('Christopher ', 'Christopher '),\n",
       " ('Neural Networks', 'Neural Networks'),\n",
       " ('In Allen ', 'In Allen '),\n",
       " ('Science Handbook', 'Science Handbook'),\n",
       " ('Second Edition ', 'Second Edition '),\n",
       " ('Section ', 'Section '),\n",
       " ('Intelligent Systems', 'Intelligent Systems'),\n",
       " ('Raton', 'Raton'),\n",
       " ('Florida', 'Florida'),\n",
       " ('Chapman ', 'Chapman '),\n",
       " ('Hall', 'Hall'),\n",
       " ('Press ', 'Press '),\n",
       " ('Otterlo', 'Otterlo'),\n",
       " ('Wiering', 'Wiering'),\n",
       " ('Learning', 'Learning'),\n",
       " ('Learning', 'Learning'),\n",
       " ('Optimization', 'Optimization'),\n",
       " ('Bozinovski', 'Bozinovski'),\n",
       " ('Trappl', 'Trappl'),\n",
       " ('Robert ', 'Robert '),\n",
       " ('Systems Research', 'Systems Research'),\n",
       " ('Proceedings ', 'Proceedings '),\n",
       " ('Sixth European Meeting ', 'Sixth European Meeting '),\n",
       " ('Cybernetics ', 'Cybernetics '),\n",
       " ('Systems Research', 'Systems Research'),\n",
       " ('Holland', 'Holland'),\n",
       " ('Bozinovski', 'Bozinovski'),\n",
       " ('Stevo ', 'Stevo '),\n",
       " ('Modeling ', 'Modeling '),\n",
       " ('Procedia Computer Science ', 'Procedia Computer Science '),\n",
       " ('Bozinovski', 'Bozinovski'),\n",
       " ('Self', 'Self'),\n",
       " ('Cybernetics ', 'Cybernetics '),\n",
       " ('Systems ', 'Systems '),\n",
       " ('Representation Learning', 'Representation Learning'),\n",
       " ('Review ', 'Review '),\n",
       " ('New Perspectives', 'New Perspectives'),\n",
       " ('Transactions ', 'Transactions '),\n",
       " ('Pattern Analysis ', 'Pattern Analysis '),\n",
       " ('Machine Intelligence', 'Machine Intelligence'),\n",
       " ('Xiv', 'Xiv'),\n",
       " ('Nathan Srebro', 'Nathan Srebro'),\n",
       " ('Jason ', 'Jason '),\n",
       " ('Tommi ', 'Tommi '),\n",
       " ('Margin Matrix Factorization', 'Margin Matrix Factorization'),\n",
       " ('Coates', 'Coates'),\n",
       " ('Adam', 'Adam'),\n",
       " ('Lee', 'Lee'),\n",
       " ('Honglak', 'Honglak'),\n",
       " ('Ng', 'Ng'),\n",
       " ('Andrew ', 'Andrew '),\n",
       " ('Conf', 'Conf'),\n",
       " ('Statistics ', 'Statistics '),\n",
       " ('Csurka', 'Csurka'),\n",
       " ('Gabriella', 'Gabriella'),\n",
       " ('Dance', 'Dance'),\n",
       " ('Christopher ', 'Christopher '),\n",
       " ('Fan', 'Fan'),\n",
       " ('Lixin', 'Lixin'),\n",
       " ('Willamowski', 'Willamowski'),\n",
       " ('Jutta', 'Jutta'),\n",
       " ('Bray', 'Bray'),\n",
       " ('Workshop ', 'Workshop '),\n",
       " ('Statistical Learning ', 'Statistical Learning '),\n",
       " ('Computer Vision', 'Computer Vision'),\n",
       " ('Daniel Jurafsky', 'Daniel Jurafsky'),\n",
       " ('James ', 'James '),\n",
       " ('Language Processing', 'Language Processing'),\n",
       " ('Education International', 'Education International'),\n",
       " ('Lu', 'Lu'),\n",
       " ('Haiping', 'Haiping'),\n",
       " ('Plataniotis', 'Plataniotis'),\n",
       " ('Venetsanopoulos', 'Venetsanopoulos'),\n",
       " ('Survey ', 'Survey '),\n",
       " ('Multilinear Subspace Learning ', 'Multilinear Subspace Learning '),\n",
       " ('Tensor Data', 'Tensor Data'),\n",
       " ('Recognition', 'Recognition'),\n",
       " ('Yoshua Bengio ', 'Yoshua Bengio '),\n",
       " ('Deep Architectures ', 'Deep Architectures '),\n",
       " ('Publishers Inc', 'Publishers Inc'),\n",
       " ('Tillmann', 'Tillmann'),\n",
       " ('On ', 'On '),\n",
       " ('Computational Intractability ', 'Computational Intractability '),\n",
       " ('Exact ', 'Exact '),\n",
       " ('Approximate Dictionary Learning', 'Approximate Dictionary Learning'),\n",
       " ('Signal Processing Letters', 'Signal Processing Letters'),\n",
       " ('Xiv', 'Xiv'),\n",
       " ('Aharon', 'Aharon'),\n",
       " ('Elad', 'Elad'),\n",
       " ('Bruckstein', 'Bruckstein'),\n",
       " ('An Algorithm ', 'An Algorithm '),\n",
       " ('Designing Overcomplete Dictionaries ',\n",
       "  'Designing Overcomplete Dictionaries '),\n",
       " ('Sparse Representation', 'Sparse Representation'),\n",
       " ('Signal Processing', 'Signal Processing'),\n",
       " ('Transactions ', 'Transactions '),\n",
       " ('Zimek', 'Zimek'),\n",
       " ('Arthur', 'Arthur'),\n",
       " ('Schubert', 'Schubert'),\n",
       " ('Erich ', 'Erich '),\n",
       " ('Outlier Detection', 'Outlier Detection'),\n",
       " ('Encyclopedia ', 'Encyclopedia '),\n",
       " ('Database Systems', 'Database Systems'),\n",
       " ('Springer New York', 'Springer New York'),\n",
       " ('Hodge', 'Hodge'),\n",
       " ('Austin', 'Austin'),\n",
       " ('Survey ', 'Survey '),\n",
       " ('Outlier Detection Methodologies', 'Outlier Detection Methodologies'),\n",
       " ('Intelligence Review', 'Intelligence Review'),\n",
       " ('Seer', 'Seer'),\n",
       " ('Dokas', 'Dokas'),\n",
       " ('Paul', 'Paul'),\n",
       " ('Ertoz', 'Ertoz'),\n",
       " ('Levent', 'Levent'),\n",
       " ('Kumar', 'Kumar'),\n",
       " ('Vipin', 'Vipin'),\n",
       " ('Lazarevic', 'Lazarevic'),\n",
       " ('Aleksandar', 'Aleksandar'),\n",
       " ('Srivastava', 'Srivastava'),\n",
       " ('Jaideep', 'Jaideep'),\n",
       " ('Tan', 'Tan'),\n",
       " ('Pang', 'Pang'),\n",
       " ('Ning ', 'Ning '),\n",
       " ('Data ', 'Data '),\n",
       " ('Workshop ', 'Workshop '),\n",
       " ('Next Generation Data Mining', 'Next Generation Data Mining'),\n",
       " ('Chandola', 'Chandola'),\n",
       " ('Banerjee', 'Banerjee'),\n",
       " ('Kumar', 'Kumar'),\n",
       " ('Anomaly ', 'Anomaly '),\n",
       " ('Computing Surveys', 'Computing Surveys'),\n",
       " ('Piatetsky', 'Piatetsky'),\n",
       " ('Shapiro', 'Shapiro'),\n",
       " ('Gregory ', 'Gregory '),\n",
       " ('Discovery', 'Discovery'),\n",
       " ('Piatetsky', 'Piatetsky'),\n",
       " ('Shapiro', 'Shapiro'),\n",
       " ('Gregory', 'Gregory'),\n",
       " ('Frawley', 'Frawley'),\n",
       " ('William ', 'William '),\n",
       " ('Knowledge Discovery ', 'Knowledge Discovery '),\n",
       " ('Databases', 'Databases'),\n",
       " ('Press', 'Press'),\n",
       " ('Cambridge', 'Cambridge'),\n",
       " ('Bassel', 'Bassel'),\n",
       " ('George ', 'George '),\n",
       " ('Glaab', 'Glaab'),\n",
       " ('Enrico', 'Enrico'),\n",
       " ('Marquez', 'Marquez'),\n",
       " ('Julietta', 'Julietta'),\n",
       " ('Holdsworth', 'Holdsworth'),\n",
       " ('Michael ', 'Michael '),\n",
       " ('Bacardit', 'Bacardit'),\n",
       " ('Jaume ', 'Jaume '),\n",
       " ('Functional Network Construction ', 'Functional Network Construction '),\n",
       " ('Arabidopsis Using Rule', 'Arabidopsis Using Rule'),\n",
       " ('Based Machine Learning ', 'Based Machine Learning '),\n",
       " ('Large', 'Large'),\n",
       " ('Scale Data Sets', 'Scale Data Sets'),\n",
       " ('Plant Cell', 'Plant Cell'),\n",
       " ('Agrawal', 'Agrawal'),\n",
       " ('Imieli', 'Imieli'),\n",
       " ('Swami', 'Swami'),\n",
       " ('Mining ', 'Mining '),\n",
       " ('Management ', 'Management '),\n",
       " ('Seer', 'Seer'),\n",
       " ('Urbanowicz', 'Urbanowicz'),\n",
       " ('Ryan ', 'Ryan '),\n",
       " ('Moore', 'Moore'),\n",
       " ('Jason ', 'Jason '),\n",
       " ('Learning Classifier Systems', 'Learning Classifier Systems'),\n",
       " ('Complete Introduction', 'Complete Introduction'),\n",
       " ('Review', 'Review'),\n",
       " ('Roadmap', 'Roadmap'),\n",
       " ('Artificial Evolution ', 'Artificial Evolution '),\n",
       " ('Applications', 'Applications'),\n",
       " ('Plotkin ', 'Plotkin '),\n",
       " ('Methods ', 'Methods '),\n",
       " ('Inductive Inference', 'Inductive Inference'),\n",
       " ('Ph', 'Ph'),\n",
       " ('University ', 'University '),\n",
       " ('Edinburgh', 'Edinburgh'),\n",
       " ('Shapiro', 'Shapiro'),\n",
       " ('Ehud ', 'Ehud '),\n",
       " ('Research Report ', 'Research Report '),\n",
       " ('Yale University', 'Yale University'),\n",
       " ('Department ', 'Department '),\n",
       " ('Computer Science', 'Computer Science'),\n",
       " ('Eds', 'Eds'),\n",
       " ('Computational Logic', 'Computational Logic'),\n",
       " ('The ', 'The '),\n",
       " ('Press', 'Press'),\n",
       " ('Cambridge', 'Cambridge'),\n",
       " ('Shapiro', 'Shapiro'),\n",
       " ('Ehud ', 'Ehud '),\n",
       " ('Mass', 'Mass'),\n",
       " ('Press', 'Press'),\n",
       " ('Shapiro', 'Shapiro'),\n",
       " ('Ehud ', 'Ehud '),\n",
       " ('The ', 'The '),\n",
       " ('Proceedings ', 'Proceedings '),\n",
       " ('Artificial ', 'Artificial '),\n",
       " ('Volume ', 'Volume '),\n",
       " ('Kaufmann Publishers Inc', 'Kaufmann Publishers Inc'),\n",
       " ('Honglak Lee', 'Honglak Lee'),\n",
       " ('Roger Grosse', 'Roger Grosse'),\n",
       " ('Rajesh Ranganath', 'Rajesh Ranganath'),\n",
       " ('Andrew ', 'Andrew '),\n",
       " ('Ng. ', 'Ng. '),\n",
       " ('Convolutional Deep Belief Networks ',\n",
       "  'Convolutional Deep Belief Networks '),\n",
       " ('Scalable Unsupervised Learning ', 'Scalable Unsupervised Learning '),\n",
       " ('Hierarchical Representations', 'Hierarchical Representations'),\n",
       " ('Proceedings ', 'Proceedings '),\n",
       " ('Annual International Conference ', 'Annual International Conference '),\n",
       " ('Machine Learning', 'Machine Learning'),\n",
       " ('Cortes', 'Cortes'),\n",
       " ('Corinna', 'Corinna'),\n",
       " ('Vapnik', 'Vapnik'),\n",
       " ('Vladimir ', 'Vladimir '),\n",
       " ('Support', 'Support'),\n",
       " ('Learning', 'Learning'),\n",
       " ('Stevenson', 'Stevenson'),\n",
       " ('Christopher', 'Christopher'),\n",
       " ('Tutorial', 'Tutorial'),\n",
       " ('Polynomial Regression ', 'Polynomial Regression '),\n",
       " ('Excel', 'Excel'),\n",
       " ('January ', 'January '),\n",
       " ('Goldberg', 'Goldberg'),\n",
       " ('David ', 'David '),\n",
       " ('Holland', 'Holland'),\n",
       " ('John ', 'John '),\n",
       " ('Genetic ', 'Genetic '),\n",
       " ('Learning', 'Learning'),\n",
       " ('Michie', 'Michie'),\n",
       " ('Spiegelhalter', 'Spiegelhalter'),\n",
       " ('Taylor', 'Taylor'),\n",
       " ('Machine Learning', 'Machine Learning'),\n",
       " ('Neural ', 'Neural '),\n",
       " ('Statistical Classification', 'Statistical Classification'),\n",
       " ('Horwood Series ', 'Horwood Series '),\n",
       " ('Artificial Intelligence', 'Artificial Intelligence'),\n",
       " ('Zhang', 'Zhang'),\n",
       " ('Jun', 'Jun'),\n",
       " ('Zhan', 'Zhan'),\n",
       " ('Zhi', 'Zhi'),\n",
       " ('Lin', 'Lin'),\n",
       " ('Ying', 'Ying'),\n",
       " ('Chen', 'Chen'),\n",
       " ('Ni', 'Ni'),\n",
       " ('Gong', 'Gong'),\n",
       " ('Yue', 'Yue'),\n",
       " ('Zhong', 'Zhong'),\n",
       " ('Jing', 'Jing'),\n",
       " ('Chung', 'Chung'),\n",
       " ('Henry ', 'Henry '),\n",
       " ('Li', 'Li'),\n",
       " ('Yun', 'Yun'),\n",
       " ('Shi', 'Shi'),\n",
       " ('Yu', 'Yu'),\n",
       " ('Evolutionary Computation Meets Machine Learning',\n",
       "  'Evolutionary Computation Meets Machine Learning'),\n",
       " ('Survey', 'Survey'),\n",
       " ('Intelligence Magazine', 'Intelligence Magazine'),\n",
       " ('Federated Learning', 'Federated Learning'),\n",
       " ('Collaborative Machine Learning ', 'Collaborative Machine Learning '),\n",
       " ('Centralized Training Data', 'Centralized Training Data'),\n",
       " ('Blog', 'Blog'),\n",
       " ('BelKor Home Page', 'BelKor Home Page'),\n",
       " ('The Netflix Tech Blog', 'The Netflix Tech Blog'),\n",
       " ('Netflix Recommendations', 'Netflix Recommendations'),\n",
       " ('Beyond ', 'Beyond '),\n",
       " ('Part ', 'Part '),\n",
       " ('August ', 'August '),\n",
       " ('Scott Patterson ', 'Scott Patterson '),\n",
       " ('July ', 'July '),\n",
       " ('Letting ', 'Letting '),\n",
       " ('Machines Decide', 'Machines Decide'),\n",
       " ('Wall Street Journal', 'Wall Street Journal'),\n",
       " ('June ', 'June '),\n",
       " ('Vinod Khosla ', 'Vinod Khosla '),\n",
       " ('January ', 'January '),\n",
       " ('Do We Need Doctors ', 'Do We Need Doctors '),\n",
       " ('Algorithms', 'Algorithms'),\n",
       " ('Crunch', 'Crunch'),\n",
       " ('When ', 'When '),\n",
       " ('Machine Learning Algorithm Studied Fine Art Paintings',\n",
       "  'Machine Learning Algorithm Studied Fine Art Paintings'),\n",
       " ('It Saw Things Art Historians Had Never Noticed',\n",
       "  'It Saw Things Art Historians Had Never Noticed'),\n",
       " ('The Physics ', 'The Physics '),\n",
       " ('ArXiv ', 'ArXiv '),\n",
       " ('Vincent', 'Vincent'),\n",
       " ('James ', 'James '),\n",
       " ('The ', 'The '),\n",
       " ('Verge', 'Verge'),\n",
       " ('Why Machine Learning Models Often Fail ',\n",
       "  'Why Machine Learning Models Often Fail '),\n",
       " ('Learn', 'Learn'),\n",
       " ('QuickTake ', 'QuickTake '),\n",
       " ('The First Wave ', 'The First Wave '),\n",
       " ('Corporate ', 'Corporate '),\n",
       " ('Is Doomed ', 'Is Doomed '),\n",
       " ('Fail', 'Fail'),\n",
       " ('Business Review', 'Business Review'),\n",
       " ('Why ', 'Why '),\n",
       " ('Beat', 'Beat'),\n",
       " ('Reasons ', 'Reasons '),\n",
       " ('Why Uber', 'Why Uber'),\n",
       " ('Economist', 'Economist'),\n",
       " ('Watson ', 'Watson '),\n",
       " ('Hernandez', 'Hernandez'),\n",
       " ('Daniela', 'Daniela'),\n",
       " ('Greenwald', 'Greenwald'),\n",
       " ('Ted ', 'Ted '),\n",
       " ('Has ', 'Has '),\n",
       " ('Watson Dilemma', 'Watson Dilemma'),\n",
       " ('Street Journal', 'Street Journal'),\n",
       " ('Garcia', 'Garcia'),\n",
       " ('Megan ', 'Megan '),\n",
       " ('Racist ', 'Racist '),\n",
       " ('Machine', 'Machine'),\n",
       " ('Policy Journal', 'Policy Journal'),\n",
       " ('Caliskan', 'Caliskan'),\n",
       " ('Aylin', 'Aylin'),\n",
       " ('Bryson', 'Bryson'),\n",
       " ('Joanna ', 'Joanna '),\n",
       " ('Narayanan', 'Narayanan'),\n",
       " ('Arvind ', 'Arvind '),\n",
       " ('Semantics ', 'Semantics '),\n",
       " ('Xiv', 'Xiv'),\n",
       " ('Sci', 'Sci'),\n",
       " ('Wang', 'Wang'),\n",
       " ('Xinan', 'Xinan'),\n",
       " ('Dasgupta', 'Dasgupta'),\n",
       " ('Sanjoy ', 'Sanjoy '),\n",
       " ('Lee', 'Lee'),\n",
       " ('Sugiyama', 'Sugiyama'),\n",
       " ('Luxburg', 'Luxburg'),\n",
       " ('Guyon', 'Guyon'),\n",
       " ('An ', 'An '),\n",
       " ('Advances ', 'Advances '),\n",
       " ('Neural Information Processing Systems ',\n",
       "  'Neural Information Processing Systems '),\n",
       " ('Curran Associates', 'Curran Associates'),\n",
       " ('Inc', 'Inc'),\n",
       " ('Julia Angwin', 'Julia Angwin'),\n",
       " ('Jeff Larson', 'Jeff Larson'),\n",
       " ('Lauren Kirchner', 'Lauren Kirchner'),\n",
       " ('Surya Mattu ', 'Surya Mattu '),\n",
       " ('Machine Bias', 'Machine Bias'),\n",
       " ('Publica', 'Publica'),\n",
       " ('Opinion ', 'Opinion '),\n",
       " ('When ', 'When '),\n",
       " ('Algorithm Helps Send You ', 'Algorithm Helps Send You '),\n",
       " ('Prison', 'Prison'),\n",
       " ('York Times', 'York Times'),\n",
       " ('Google ', 'Google '),\n",
       " ('News', 'News'),\n",
       " ('Google ', 'Google '),\n",
       " ('Verge', 'Verge'),\n",
       " ('Opinion ', 'Opinion '),\n",
       " ('Artificial Intelligence', 'Artificial Intelligence'),\n",
       " ('White Guy Problem', 'White Guy Problem'),\n",
       " ('York Times', 'York Times'),\n",
       " ('Metz', 'Metz'),\n",
       " ('Rachel', 'Rachel'),\n",
       " ('Why Microsoft', 'Why Microsoft'),\n",
       " ('Tay', 'Tay'),\n",
       " ('Technology Review', 'Technology Review'),\n",
       " ...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c=simple_get('https://en.wikipedia.org/wiki/Machine_learning')\n",
    "html=BeautifulSoup(c,'html.parser')\n",
    "re.findall(r'(([A-Z][a-z]{1,2}\\.\\s+(?:[A-Z][a-z]+\\s*)*|(?<!\\. )(?<!;)(?:[A-Z][a-z]+\\s*)+))'  ,html.body.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
